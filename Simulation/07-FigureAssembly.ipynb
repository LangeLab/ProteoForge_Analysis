{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d416874d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "title: Notebook S7\n",
    "author: Enes Kemal Ergin\n",
    "date: \"{{ datetime.now().strftime('%Y-%m-%d %H:%M:%S') }}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaabf3a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Supplementary Notebook S7: Highly Summarized Plots for Assembling the Figure 2\n",
    "\n",
    "- **License:** [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/)\n",
    "- **Version:** 0.1\n",
    "- **Edit Log:** \n",
    "    - 2025-11-28: Initial version of the notebook\n",
    "\n",
    "---\n",
    "\n",
    "**Requirements:**  \n",
    "\n",
    "The following preprocessing and method runs must be completed (in order) before executing this notebook:\n",
    "\n",
    "1. `01-SimulatedDatasets.ipynb` - Prepares simulated datasets with various perturbation scenarios.\n",
    "2. `02-runCOPF.R` - Executes the COPF method on the simulated datasets.\n",
    "3. `03-runPeCorA.R` - Executes the PeCorA method on the simulated datasets.\n",
    "4. `04-runProteoForge.R` - Executes the ProteoForge method on the simulated datasets.\n",
    "5. `05-IdentificationBenchmark.ipynb` - Generates the peptide identification benchmark figures, and combines results from all methods.\n",
    "6. `06-GroupingBenchmark.ipynb` - Generates the peptide grouping benchmark figures, and combines results from all methods.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Data Information:**\n",
    "\n",
    "This notebooks uses the final combined benchmarking results table from the real-data benchmarking (../Benchmark/) and simulated benchmarking (./) analyses. From 1 real-data, and 4 simulated setups, 2 benchmarks (peptide identification and peptide grouping) were used.\n",
    "\n",
    "---\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "This notebook compiles key performance plots from previous analyses into a cohesive figure for publication. It focuses on summarizing the ROC curves and optimal F1/MCC thresholds across different perturbation scenarios and methods (COPF, PeCorA, ProteoForge). The final figure highlights comparative strengths and weaknesses of each approach in detecting proteoform changes under various conditions. This figure is meant to be very high-level and concise to go into the main figures, whereas the detailed plots and analyses are available in the supplementary notebooks as well as placed into supplementary figures.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "This section imports required libraries, configures display settings, and defines paths for data and figures.\n",
    "\n",
    "> **Note:** The HTML rendering of this notebook hides code cells by default. Click the \"Code\" buttons on the right to expand them.\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np # Numerical computing\n",
    "import pandas as pd # Data manipulatio\n",
    "\n",
    "import seaborn as sns # R-like high-level plots\n",
    "import matplotlib.pyplot as plt # Python's base plotting \n",
    "\n",
    "sys.path.append('../')\n",
    "from src import utils, plots\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize the timer\n",
    "startTime = utils.getTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74049e2",
   "metadata": {},
   "source": [
    "### Display Settings\n",
    "\n",
    "The cell below configures pandas, matplotlib, and seaborn display options for improved readability of tables and figures, including color palettes and figure export settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default colors and styles for plots\n",
    "def_colors = [\n",
    "    \"#139593\", \"#fca311\", \"#e54f2a\",\n",
    "    \"#c3c3c3\", \"#555555\",\n",
    "    \"#690000\", \"#5f4a00\", \"#004549\"\n",
    "]\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_theme(\n",
    "    style=\"white\",\n",
    "    context=\"paper\",\n",
    "    palette=def_colors,\n",
    "    font_scale=1,\n",
    "    rc={\n",
    "        \"figure.figsize\": (6, 4),\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Arial\", \"Ubuntu Mono\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Figure Saving Settings\n",
    "figure_formats = [\"pdf\"]\n",
    "save_to_folder = True\n",
    "transparent_bg = True\n",
    "figure_dpi = 300\n",
    "\n",
    "## Configure dataframe displaying\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 500)  # Set a wider display width\n",
    "\n",
    "## Printing Settings\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845432c1",
   "metadata": {},
   "source": [
    "### Data and Result Paths\n",
    "\n",
    "Data and figures are organized in separate folders:\n",
    "\n",
    "- `data_path` — Not one directory is needed as data is read from both the real-data benchmarking (`../Benchmark/data/prepared/`) and simulated benchmarking (`./data/prepared/`) analyses. They are explicitly added to each file-reading step.\n",
    "- `figure_path` — Directory for generated plots and figures (`figures/07-FigureAssembly/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca36612",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = \"07-FigureAssembly\"\n",
    "figure_path = f\"./figures/{notebook_name}/\"\n",
    "\n",
    "# Create figure folder structure, if needed\n",
    "if save_to_folder:\n",
    "    for i in figure_formats:\n",
    "        cur_folder = figure_path + i + \"/\"\n",
    "        if not os.path.exists(cur_folder):\n",
    "            os.makedirs(cur_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f23138",
   "metadata": {},
   "source": [
    "### Global Variables\n",
    "\n",
    "Defines constants and visual styling for consistent analysis and publication-quality figures:\n",
    "\n",
    "- **`seed`** — Random seed for reproducibility\n",
    "- **`pthr`** — P-value threshold (10⁻³) for statistical significance\n",
    "- **`method_palette`** / **`method_markers`** — Color and marker scheme for methods (COPF, PeCorA, ProteoForge)\n",
    "- **`mcc_thresholds`** / **`mcc_colors`** — MCC interpretation scale with semantic labels (Random → Almost Perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "seed = 42 # Seed for reproducibility  \n",
    "pthr = 10**-3  # p-value threshold for significance\n",
    "thresholds = list(utils.generate_thresholds(10.0, -15, 1, 0, 1, 0.1)) # Thresholds for the analysis\n",
    "\n",
    "# Methods and their plotting styles\n",
    "method_palette = {\n",
    "    \"COPF\": \"#139593\",\n",
    "    \"PeCorA\": \"#fca311\",\n",
    "    \"ProteoForge\": \"#e54f2a\",\n",
    "}\n",
    "method_styles = {\n",
    "    \"COPF\": \"--\",\n",
    "    \"PeCorA\": \"-.\",\n",
    "    \"ProteoForge\": \":\",\n",
    "}\n",
    "method_markers = {\n",
    "    \"COPF\": \"o\",\n",
    "    \"PeCorA\": \"s\",\n",
    "    \"ProteoForge\": \"^\",\n",
    "}\n",
    "\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC) thresholds and colors\n",
    "mcc_thresholds = {\n",
    "    0.0 : 'Random',\n",
    "    0.3 : 'Fair (0.3)',\n",
    "    0.5 : 'Moderate (0.5)',\n",
    "    0.7 : 'Strong (0.7)',\n",
    "    0.9 : 'Almost Perfect (0.9)',\n",
    "}\n",
    "mcc_colors = {\n",
    "    'Random': '#c3c3c3',             \n",
    "    'Fair (0.3)': '#e0aaff',         \n",
    "    'Moderate (0.5)': '#9d4edd',     \n",
    "    'Strong (0.7)': '#5a189a',       \n",
    "    'Almost Perfect (0.9)': '#240046' \n",
    "}\n",
    "\n",
    "plots.color_palette(mcc_colors, save=False, name=\"MCC Interpretation Colors\")\n",
    "plots.color_palette(method_palette, save=False, name=\"Method Colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594857a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Figure 2: Method Benchmarking Overview\n",
    "\n",
    "This figure compiles performance comparisons of ProteoForge against established methods (COPF, PeCorA) using both real-world SWATH-MS data and controlled simulations. The benchmarks evaluate two core tasks: **Peptide Identification** (detecting which peptides are perturbed) and **Peptide Grouping** (correctly assigning perturbed peptides to proteoform groups).\n",
    "\n",
    "### 2.1 SWATH-MS Benchmark: Real-World Performance\n",
    "\n",
    "**Data Source:** COPF manuscript benchmark dataset (analyzed in `../Benchmark/` notebooks)\n",
    "\n",
    "**Key Question:** How do methods compare on experimentally validated proteoform perturbations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fe811",
   "metadata": {},
   "outputs": [],
   "source": [
    "swath_pepid = pd.read_feather(\"../Benchmark/data/results/peptide_identification_performance_data.feather\")\n",
    "swath_pepgrp = pd.read_feather(\"../Benchmark/data/results/peptide_grouping_performance_data.feather\")\n",
    "# Combine as swath with Benchmark column indicating pepID, or pepGrp\n",
    "swath_pepgrp['Benchmark'] = 'Peptide Grouping'\n",
    "swath_pepid['Benchmark'] = 'Peptide Identification'\n",
    "swath_combined = pd.concat(\n",
    "    [swath_pepid, swath_pepgrp], ignore_index=True\n",
    ").rename(columns={\n",
    "    'perturbation': 'Experiment',\n",
    "    'method': 'Method',\n",
    "})\n",
    "# swath_combined['Experiment'].value_counts()\n",
    "# Replace the Experiment to standardize the naming:\n",
    "swath_combined['Experiment'] = swath_combined['Experiment'].replace({\n",
    "    '1 Peptide': '1 Peptide',\n",
    "    '2 Peptides': '2 Peptides',\n",
    "    '%50 Peptides': '50% Peptides',\n",
    "    'Random (1 to %50) Peptides': 'Random Peptides',\n",
    "    'Random (2 to %50) Peptides': 'Random Peptides',\n",
    "})\n",
    "swath_combined['Experiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74414577",
   "metadata": {},
   "source": [
    "#### MCC Performance Across Perturbation Scenarios\n",
    "\n",
    "The barplot compares Matthews Correlation Coefficient (MCC) across four perturbation scenarios:\n",
    "- **1 Peptide / 2 Peptides**: Single or paired peptide perturbations\n",
    "- **Random Peptides**: Variable number (2–50%) of peptides perturbed\n",
    "- **50% Peptides**: Half of all peptides perturbed\n",
    "\n",
    "**Visual Elements:**\n",
    "- Bars show mean MCC (± 95% CI) across thresholds\n",
    "- Scatter points indicate MCC at p-value threshold (10⁻³)\n",
    "- Horizontal reference lines denote MCC interpretation thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff798a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def compute_offset(n_methods, idx_method, total_width=0.8):\n",
    "    # Calculates the horizontal offset for aligning elements with grouped bars.\n",
    "    if n_methods <= 1:\n",
    "        return 0.0\n",
    "    single_width = total_width / n_methods\n",
    "    center_offset = (n_methods - 1) / 2.0\n",
    "    return (idx_method - center_offset) * single_width\n",
    "\n",
    "def plot_benchmark_panel(ax, data, x_order, hue_order, palette, markers, p_threshold):\n",
    "    # Generates a single panel with a bar plot, score annotations, and scatter points.\n",
    "    sns.barplot(\n",
    "        ax=ax, data=data, x='Experiment', y='MCC', hue='Method',\n",
    "        order=x_order, hue_order=hue_order, palette=palette,\n",
    "        edgecolor=\"black\", linewidth=1.0, errorbar=\"ci\",\n",
    "        capsize=0.03, err_kws={'linewidth': 1.0}\n",
    "    )\n",
    "\n",
    "    n_methods = len(hue_order)\n",
    "    pthr_data = data[data['threshold'] == p_threshold]\n",
    "\n",
    "    for i, experiment in enumerate(x_order):\n",
    "        for j, method in enumerate(hue_order):\n",
    "            offset = compute_offset(n_methods, j)\n",
    "            x_pos = i + offset\n",
    "\n",
    "            mean_mcc = data[(data[\"Experiment\"] == experiment) & (data[\"Method\"] == method)][\"MCC\"].mean()\n",
    "            if not np.isnan(mean_mcc):\n",
    "                ax.text(\n",
    "                    x_pos, -0.03, f\"{mean_mcc:.2f}\", color=palette.get(method, 'k'),\n",
    "                    ha=\"center\", va=\"top\", fontsize=8, fontweight=\"bold\", rotation=90,\n",
    "                )\n",
    "\n",
    "            method_pthr_data = pthr_data[(pthr_data['Method'] == method) & (pthr_data['Experiment'] == experiment)]\n",
    "            if not method_pthr_data.empty:\n",
    "                y_pos = method_pthr_data['MCC'].iloc[0]\n",
    "                ax.scatter(\n",
    "                    x_pos, y_pos, color=palette.get(method, 'k'), s=60,\n",
    "                    edgecolor='black', linewidth=1.0, marker=markers.get(method, 'o'),\n",
    "                    zorder=10, alpha=0.95\n",
    "                )\n",
    "    \n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", linewidth=0.5, alpha=0.7, color=\"gray\")\n",
    "    ax.set_xlabel('')\n",
    "    ax.tick_params(axis='x', labelsize=9, rotation=90) # Rotate x-axis labels\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    if ax.get_legend() is not None:\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "# Filter and categorize data for plotting\n",
    "experiments_ordered = ['1 Peptide', '2 Peptides', 'Random Peptides', '50% Peptides']\n",
    "methods_ordered_pepid = ['ProteoForge', 'PeCorA', 'COPF']\n",
    "methods_ordered_pepgrp = ['ProteoForge', 'COPF']\n",
    "\n",
    "subset_pepid = swath_combined[(swath_combined['Benchmark'] == 'Peptide Identification') & (swath_combined['Experiment'].isin(experiments_ordered))].copy()\n",
    "subset_pepid['Experiment'] = pd.Categorical(subset_pepid['Experiment'], categories=experiments_ordered, ordered=True)\n",
    "subset_pepid['Method'] = pd.Categorical(subset_pepid['Method'], categories=methods_ordered_pepid, ordered=True)\n",
    "\n",
    "subset_pepgrp = swath_combined[(swath_combined['Benchmark'] == 'Peptide Grouping') & (swath_combined['Experiment'].isin(experiments_ordered))].copy()\n",
    "subset_pepgrp['Experiment'] = pd.Categorical(subset_pepgrp['Experiment'], categories=experiments_ordered, ordered=True)\n",
    "subset_pepgrp['Method'] = pd.Categorical(subset_pepgrp['Method'], categories=methods_ordered_pepgrp, ordered=True)\n",
    "    \n",
    "# --- Figure Creation ---\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "# Adjust width ratios: ax1 wider (3 groups), ax2 narrower (2 groups)\n",
    "gs = GridSpec(2, 20, height_ratios=[1, 0.15], hspace=0.4, wspace=0.025)\n",
    "ax1 = fig.add_subplot(gs[0, :12])  # ax1: wider (12/20)\n",
    "ax2 = fig.add_subplot(gs[0, 12:18], sharey=ax1)  # ax2: narrower (6/20)\n",
    "ax_legend = fig.add_subplot(gs[1, :])\n",
    "ax_legend.axis('off')\n",
    "\n",
    "# Plot Peptide Identification panel\n",
    "plot_benchmark_panel(ax1, subset_pepid, experiments_ordered, methods_ordered_pepid, method_palette, method_markers, pthr)\n",
    "ax1.set_title(\"Peptide Identification\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"MCC Score\", fontsize=10)\n",
    "ax1.set_ylim(-0.1, 1.05)\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "# Draw MCC interpretation thresholds\n",
    "for i, (thresh, label) in enumerate(mcc_thresholds.items()):\n",
    "    ax1.axhline(\n",
    "        thresh, color=mcc_colors[label], alpha=1,\n",
    "        linestyle=\"dotted\", linewidth=1.5, \n",
    "        label=label, zorder=0\n",
    "    )\n",
    "    ax1.text(\n",
    "        0.01,\n",
    "        thresh,\n",
    "        label,\n",
    "        color=mcc_colors[label],\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=8,\n",
    "        fontweight=\"bold\",\n",
    "        transform=ax1.get_yaxis_transform(),\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor=mcc_colors[label], alpha=0.8),\n",
    "        zorder=0\n",
    "    )\n",
    "\n",
    "# Plot Peptide Grouping panel\n",
    "plot_benchmark_panel(ax2, subset_pepgrp, experiments_ordered, methods_ordered_pepgrp, method_palette, method_markers, pthr)\n",
    "ax2.set_title(\"Peptide Grouping\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Set ylims (-0.15, to 0.75)\n",
    "ax1.set_ylim(-0.15, 0.75)\n",
    "ax2.set_ylim(-0.15, 0.75)\n",
    "\n",
    "# Add threshold lines (without text) to the second plot\n",
    "for thresh, label in mcc_thresholds.items():\n",
    "    ax2.axhline(thresh, color=mcc_colors[label], alpha=0.9, linestyle=\":\", linewidth=1.2, zorder=0)\n",
    "\n",
    "# --- Unified Legend ---\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=method_markers[m], color='w', markerfacecolor=method_palette[m],\n",
    "           markeredgecolor='black', markersize=9, label=m)\n",
    "    for m in methods_ordered_pepid\n",
    "]\n",
    "ax_legend.legend(\n",
    "    handles=legend_elements, loc='center', ncol=len(methods_ordered_pepid), \n",
    "    fontsize=10, title=\"Method\", title_fontsize=11, frameon=False\n",
    ")\n",
    "\n",
    "# --- Final Touches ---\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plots.finalize_plot(\n",
    "    fig, show=True, save=save_to_folder,\n",
    "    filename='benchmark_compact_fig2ab',\n",
    "    filepath=figure_path,\n",
    "    formats=figure_formats, \n",
    "    transparent=transparent_bg,\n",
    "    dpi=figure_dpi,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d347b0e",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "- All methods achieve Fair-to-Moderate MCC (~0.3–0.5) for identification tasks\n",
    "- Performance improves as more peptides are perturbed (1 → 2 → Random → 50%)\n",
    "- Peptide Grouping shows lower overall MCC, reflecting the increased difficulty of correctly clustering perturbed peptides\n",
    "- ProteoForge demonstrates competitive performance, particularly in the Random and 50% scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Simulation 1: Impact of Data Imputation\n",
    "\n",
    "**Objective:** Assess whether imputing missing values affects method performance compared to complete (fully quantified) datasets.\n",
    "\n",
    "**Design:** Random perturbation scenario (2–50% peptides) with matched complete vs. imputed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a41180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_pepid = pd.read_feather('./data/Sim1/4_Sim1_PeptideIdentification_PerformanceData.feather')\n",
    "sim1_pepgrp = pd.read_feather('./data/Sim1/4_Sim1_Grouping_PerformanceData.feather')\n",
    "# Combine as sim1 with Benchmark column indicating pepID, or pepGrp\n",
    "sim1_pepgrp['Benchmark'] = 'Peptide Grouping'\n",
    "sim1_pepid['Benchmark'] = 'Peptide Identification'\n",
    "sim1_combined = pd.concat([sim1_pepid, sim1_pepgrp], ignore_index=True)\n",
    "sim1_combined['Experiment'].value_counts()\n",
    "# Subset to show: '2>50% Peptides'\n",
    "sim1_combined = sim1_combined[sim1_combined['Experiment'] == '2>50% Peptides']\n",
    "# sim1_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eac6d7",
   "metadata": {},
   "source": [
    "#### Visualization Option 1: Horizontal Dumbbell Plot\n",
    "\n",
    "Shows performance change between complete (●) and imputed (■) data with connecting lines indicating magnitude and direction of change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07feb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(6, 4), sharex=True)\n",
    "fig.suptitle('Imputation Impact on Performance', fontsize=12, fontweight='bold')\n",
    "\n",
    "benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "methods_order = {\n",
    "    'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "    'Peptide Grouping': ['COPF', 'ProteoForge']\n",
    "}\n",
    "\n",
    "for idx, benchmark in enumerate(benchmarks):\n",
    "    ax = axs[idx]\n",
    "    df_bench = sim1_combined[sim1_combined['Benchmark'] == benchmark]\n",
    "    \n",
    "    # Calculate mean MCC for complete and imputed data for each method\n",
    "    means = df_bench.groupby(['Method', 'DataType'])['MCC'].mean().unstack()\n",
    "    methods = methods_order[benchmark]\n",
    "    means = means.reindex(methods)\n",
    "\n",
    "    y_pos = np.arange(len(methods))\n",
    "    \n",
    "    # Draw compact dumbbell elements\n",
    "    for i, method in enumerate(methods):\n",
    "        mcc_complete = means.loc[method, 'complete']\n",
    "        mcc_imputed = means.loc[method, 'imputed']\n",
    "        color = method_palette.get(method, 'grey')\n",
    "        \n",
    "        # Thinner connecting line\n",
    "        ax.plot([mcc_complete, mcc_imputed], [i, i], color=color, alpha=0.8, \n",
    "                linewidth=2, solid_capstyle='round', zorder=1)\n",
    "        \n",
    "        # Smaller markers\n",
    "        ax.scatter(mcc_complete, i, color='black', marker='o', s=40, zorder=2, alpha=0.9)\n",
    "        ax.scatter(mcc_imputed, i, color=color, marker='s', s=35, zorder=2)\n",
    "        \n",
    "        # Add difference annotation\n",
    "        diff = mcc_imputed - mcc_complete\n",
    "        mid_x = (mcc_complete + mcc_imputed) / 2\n",
    "        ax.text(mid_x, i + 0.15, f'{diff:+.3f}', ha='center', va='bottom', \n",
    "                fontsize=8, color=color, fontweight='bold')\n",
    "\n",
    "    # Compact aesthetics\n",
    "    ax.set_title(benchmark, fontsize=10, fontweight='bold', pad=8)\n",
    "    ax.grid(axis='x', linestyle=':', alpha=0.5)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(methods, fontsize=9)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "\n",
    "axs[-1].set_xlabel('MCC Score', fontsize=9)\n",
    "\n",
    "# Compact legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='gray', marker='o', linestyle='None', markersize=6, \n",
    "           markerfacecolor='black', label='Complete'),\n",
    "    Line2D([0], [0], color='gray', marker='s', linestyle='None', markersize=6, \n",
    "           label='Imputed'),\n",
    "]\n",
    "\n",
    "fig.legend(handles=legend_elements, loc='lower center', ncol=2, \n",
    "           bbox_to_anchor=(0.5, -0.02), fontsize=8, frameon=False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70c420",
   "metadata": {},
   "source": [
    "**Assessment:** Clear visualization of magnitude changes; distinct but uses significant whitespace.\n",
    "\n",
    "#### Visualization Option 2: Slope Graph\n",
    "\n",
    "Connects performance from \"Complete\" to \"Imputed\" conditions—effective for showing direction when changes are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
    "fig.suptitle('Performance: Complete vs Imputed Data', fontsize=12, fontweight='bold')\n",
    "\n",
    "benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "methods_order = {'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "                 'Peptide Grouping': ['COPF', 'ProteoForge']}\n",
    "\n",
    "for idx, benchmark in enumerate(benchmarks):\n",
    "    ax = axs[idx]\n",
    "    df_bench = sim1_combined[sim1_combined['Benchmark'] == benchmark]\n",
    "    \n",
    "    means = df_bench.groupby(['Method', 'DataType'])['MCC'].mean().unstack()\n",
    "    methods = methods_order[benchmark]\n",
    "    means = means.reindex(methods)\n",
    "    \n",
    "    # Create slope lines\n",
    "    x_positions = [0, 1]  # Complete at 0, Imputed at 1\n",
    "    \n",
    "    for i, method in enumerate(methods):\n",
    "        mcc_complete = means.loc[method, 'complete']\n",
    "        mcc_imputed = means.loc[method, 'imputed']\n",
    "        color = method_palette.get(method, 'grey')\n",
    "        \n",
    "        # Draw slope line\n",
    "        ax.plot(x_positions, [mcc_complete, mcc_imputed], \n",
    "                color=color, linewidth=2, alpha=0.8, marker='o', markersize=6,\n",
    "                label=method if idx == 0 else \"\")\n",
    "        \n",
    "        # Method labels at the midpoint\n",
    "        mid_y = (mcc_complete + mcc_imputed) / 2\n",
    "        ax.text(0.5, mid_y, method, ha='center', va='center', \n",
    "                fontsize=8, fontweight='bold', color=color,\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_title(benchmark, fontsize=10, fontweight='bold')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(['Complete', 'Imputed'], fontsize=9)\n",
    "    ax.set_ylabel('MCC Score' if idx == 0 else '', fontsize=9)\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_ylim(0, 0.6)  # Set consistent y-axis range\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5f006",
   "metadata": {},
   "source": [
    "**Assessment:** Small performance differences result in nearly horizontal lines—less effective for this dataset.\n",
    "\n",
    "#### Visualization Option 3: Grouped Bar Chart\n",
    "\n",
    "Traditional side-by-side comparison with hierarchical x-axis grouping methods by benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "fig.suptitle('Impact of Data Imputation', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = []\n",
    "benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "\n",
    "for benchmark in benchmarks:\n",
    "    df_bench = sim1_combined[sim1_combined['Benchmark'] == benchmark]\n",
    "    means = df_bench.groupby(['Method', 'DataType'])['MCC'].mean().unstack()\n",
    "    \n",
    "    for method in means.index:\n",
    "        complete_val = means.loc[method, 'complete']\n",
    "        imputed_val = means.loc[method, 'imputed']\n",
    "        diff = imputed_val - complete_val\n",
    "        \n",
    "        plot_data.append({\n",
    "            'Benchmark': benchmark,\n",
    "            'Method': method,\n",
    "            'Complete': complete_val,\n",
    "            'Imputed': imputed_val,\n",
    "            'Difference': diff\n",
    "        })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Create hierarchical x positions\n",
    "n_benchmarks = len(benchmarks)\n",
    "n_methods_per_bench = {'Peptide Identification': 3, 'Peptide Grouping': 2}  # COPF, PeCorA, ProteoForge vs COPF, ProteoForge\n",
    "method_order = {'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'], \n",
    "                'Peptide Grouping': ['COPF', 'ProteoForge']}\n",
    "\n",
    "x_positions = []\n",
    "labels = []\n",
    "benchmark_centers = []\n",
    "\n",
    "x = 0\n",
    "for i, benchmark in enumerate(benchmarks):\n",
    "    methods = method_order[benchmark]\n",
    "    start_x = x\n",
    "    \n",
    "    for j, method in enumerate(methods):\n",
    "        method_data = plot_df[(plot_df['Benchmark'] == benchmark) & (plot_df['Method'] == method)]\n",
    "        if not method_data.empty:\n",
    "            row = method_data.iloc[0]\n",
    "            \n",
    "            # Plot bars\n",
    "            width = 0.35\n",
    "            bar1 = ax.bar(x - width/2, row['Complete'], width, color='lightgray', \n",
    "                         edgecolor='black', alpha=0.8, label='Complete' if i == 0 and j == 0 else \"\")\n",
    "            bar2 = ax.bar(x + width/2, row['Imputed'], width,\n",
    "                         color=method_palette.get(method, 'gray'), edgecolor='black', alpha=0.9,\n",
    "                         label='Imputed' if i == 0 and j == 0 else \"\")\n",
    "            \n",
    "            # Add change indicators\n",
    "            diff = row['Difference']\n",
    "            arrow_color = 'green' if diff > 0 else 'red'\n",
    "            arrow_symbol = '↑' if diff > 0 else '↓'\n",
    "            \n",
    "            ax.text(x, max(row['Complete'], row['Imputed']) + 0.05, \n",
    "                   f'{arrow_symbol} {abs(diff):.3f}', \n",
    "                   ha='center', va='bottom', fontsize=9, \n",
    "                   color=arrow_color, fontweight='bold')\n",
    "            \n",
    "            x_positions.append(x)\n",
    "            labels.append(method)\n",
    "        \n",
    "        x += 1\n",
    "    \n",
    "    # Calculate benchmark center for labeling\n",
    "    end_x = x - 1\n",
    "    benchmark_centers.append((start_x + end_x) / 2)\n",
    "    x += 0.5  # Space between benchmarks\n",
    "\n",
    "# Set labels and ticks\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(labels, fontsize=10, rotation=45, ha='right')\n",
    "\n",
    "# Add benchmark labels as secondary x-axis\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlim(ax.get_xlim())\n",
    "ax2.set_xticks(benchmark_centers)\n",
    "ax2.set_xticklabels(benchmarks, fontsize=11, fontweight='bold')\n",
    "ax2.tick_params(axis='x', length=0)\n",
    "\n",
    "# Styling\n",
    "ax.set_ylabel('MCC Score', fontsize=11)\n",
    "ax.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "# Add vertical separator between benchmarks\n",
    "separator_x = x_positions[2] + 0.75  # Between ProteoForge (PepID) and COPF (PepGrp)\n",
    "ax.axvline(separator_x, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Legend\n",
    "handles, labels_leg = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels_leg, loc='upper left', fontsize=10, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b51b8",
   "metadata": {},
   "source": [
    "**Assessment:** Intuitive layout but horizontally expansive—better suited for supplementary material.\n",
    "\n",
    "#### Visualization Option 4: Vertical Overlapping Bars *(Selected)*\n",
    "\n",
    "Compact vertical layout overlaying imputed (colored) on complete (gray) bars with annotated differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(4, 6), sharex=True)\n",
    "fig.suptitle('MCC Performance: Complete vs Imputed Data (Random Perturbation (Sim1))', fontsize=12, fontweight='bold')\n",
    "\n",
    "benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "methods_order = {'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "                 'Peptide Grouping': ['COPF', 'ProteoForge']}\n",
    "\n",
    "for idx, benchmark in enumerate(benchmarks):\n",
    "    ax = axs[idx]\n",
    "    df_bench = sim1_combined[sim1_combined['Benchmark'] == benchmark]\n",
    "    \n",
    "    means = df_bench.groupby(['Method', 'DataType'])['MCC'].mean().unstack()\n",
    "    methods = methods_order[benchmark]\n",
    "    means = means.reindex(methods)\n",
    "    \n",
    "    y_pos = np.arange(len(methods))\n",
    "    colors = [method_palette.get(method, 'gray') for method in methods]\n",
    "    \n",
    "    # Plot complete data (baseline) as light bars\n",
    "    complete_bars = ax.barh(y_pos, means['complete'], height=0.6, \n",
    "                           color='lightgray', alpha=0.6, edgecolor='black',\n",
    "                           label='Complete Data')\n",
    "    \n",
    "    # Plot imputed data as colored bars\n",
    "    imputed_bars = ax.barh(y_pos, means['imputed'], height=0.4, \n",
    "                          color=colors, alpha=0.9, edgecolor='black',\n",
    "                          label='Imputed Data')\n",
    "    \n",
    "    # Add MCC values and differences as text\n",
    "    for i, method in enumerate(methods):\n",
    "        complete_val = means.loc[method, 'complete']\n",
    "        imputed_val = means.loc[method, 'imputed']\n",
    "        diff = imputed_val - complete_val\n",
    "        \n",
    "        # Show complete MCC value\n",
    "        ax.text(complete_val + 0.01, i + 0.15, f'{complete_val:.3f}', \n",
    "               va='center', ha='left', fontsize=9, color='black', fontweight='bold')\n",
    "        \n",
    "        # Show imputed MCC value  \n",
    "        ax.text(imputed_val + 0.01, i - 0.15, f'{imputed_val:.3f}', \n",
    "               va='center', ha='left', fontsize=9, color=colors[i], fontweight='bold')\n",
    "        \n",
    "        # Show difference with arrow\n",
    "        diff_color = 'green' if diff > 0 else 'red'\n",
    "        arrow_symbol = '↑' if diff > 0 else '↓'\n",
    "        \n",
    "        # Position difference text at the right edge\n",
    "        max_val = max(complete_val, imputed_val)\n",
    "        ax.text(max_val + 0.08, i, f'{arrow_symbol}{abs(diff):.3f}', \n",
    "               va='center', ha='left', fontsize=8, \n",
    "               color=diff_color, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round,pad=0.2', facecolor='white', \n",
    "                        edgecolor=diff_color, alpha=0.8))\n",
    "    \n",
    "    # Styling\n",
    "    # ax.set_title(benchmark, fontsize=11, fontweight='bold', pad=5)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(methods, fontsize=10, fontweight='bold')\n",
    "    if idx == 1:  # Only show x-axis label on bottom plot\n",
    "        ax.set_xlabel('MCC Score', fontsize=10)\n",
    "    ax.grid(axis='x', linestyle=':', alpha=0.4)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Set consistent x-axis limits for all subplots\n",
    "    ax.set_xlim(0, 0.7)  # Fixed range to accommodate all data\n",
    "\n",
    "# Unified legend at the bottom\n",
    "handles, labels_leg = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels_leg, loc='lower center', ncol=2, \n",
    "           bbox_to_anchor=(0.5, -0.05), fontsize=10, frameon=False)\n",
    "\n",
    "# Add explanation\n",
    "fig.text(0.5, -0.12, 'Green ↑: Improvement with imputation | Red ↓: Decline with imputation', \n",
    "         ha='center', fontsize=9, style='italic')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.12, 1, 0.95])\n",
    "plt.show()\n",
    "plots.finalize_plot(\n",
    "    fig, show=True, save=save_to_folder,\n",
    "    filename='benchmark_sim1_imputation_effect',\n",
    "    filepath=figure_path,\n",
    "    formats=figure_formats, \n",
    "    transparent=transparent_bg,\n",
    "    dpi=figure_dpi,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc30843",
   "metadata": {},
   "source": [
    "**Key Findings — Simulation 1:**\n",
    "- In peptide identification the imputation has small impact for ProteoForge and COPF but PeCorA declines sharply\n",
    "- For peptide grouping, ProteoForge actually improves with imputation while COPF decline slightly.\n",
    "    - This is due to with imputation, especially complete missingness does introduce potential new groups of peptides, proteoforge is capable of grouping them correctly whereas COPF fails to do so.\n",
    "- Selected visualization (Option 4) provides optimal information density for main figure\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Simulation 2: Effect of Missingness Level\n",
    "\n",
    "**Objective:** Quantify how increasing proportions of missing data affect detection performance.\n",
    "\n",
    "**Design:** Factorial combinations of protein-level (0–80%) × peptide-level (0–80%) missingness.\n",
    "\n",
    "**Key Questions:**\n",
    "- At what missingness threshold does performance critically degrade?\n",
    "- Do methods differ in their tolerance to incomplete data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore Sim2 data (Missingness analysis)\n",
    "sim2_pepid = pd.read_feather('./data/Sim2/4_Sim2_PeptideIdentification_PerformanceData.feather')\n",
    "sim2_pepgrp = pd.read_feather('./data/Sim2/4_Sim2_Grouping_PerformanceData.feather')\n",
    "\n",
    "# Combine data\n",
    "sim2_pepgrp['Benchmark'] = 'Peptide Grouping'\n",
    "sim2_pepid['Benchmark'] = 'Peptide Identification'\n",
    "sim2_combined = pd.concat([sim2_pepid, sim2_pepgrp], ignore_index=True)\n",
    "\n",
    "# Clean up the missingness data\n",
    "def clean_missingness_values(x):\n",
    "    if isinstance(x, str):\n",
    "        return float(x.rstrip('%')) / 100.0\n",
    "    return float(x)\n",
    "\n",
    "sim2_combined['ProteinMissingness'] = sim2_combined['ProteinMissingness'].apply(clean_missingness_values)\n",
    "sim2_combined['PeptideMissingness'] = sim2_combined['PeptideMissingness'].apply(clean_missingness_values)\n",
    "\n",
    "sim2_summary = sim2_combined.groupby(['Method', 'ProteinMissingness', 'PeptideMissingness', 'Benchmark'])['MCC'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02632fc",
   "metadata": {},
   "source": [
    "#### Visualization Option 1: Degradation Line Plots\n",
    "\n",
    "MCC trajectories as peptide missingness increases (x-axis), stratified by protein missingness levels (line styles: solid=0%, dashed=40%, dotted=80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fdd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_degradation_lines(figsize=(6, 5)):\n",
    "    \"\"\"Show how performance degrades with increasing missingness - Vertical Layout\"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "    fig.suptitle('Performance Degradation with Missingness', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "    method_sets = {\n",
    "        'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "        'Peptide Grouping': ['COPF', 'ProteoForge']  # No PeCorA for grouping\n",
    "    }\n",
    "    \n",
    "    for idx, benchmark in enumerate(benchmarks):\n",
    "        ax = axs[idx]\n",
    "        methods = method_sets[benchmark]\n",
    "        \n",
    "        # Plot lines for each method at different protein missingness levels\n",
    "        protein_levels = [0.0, 0.4, 0.8]  # Show key levels only\n",
    "        \n",
    "        for method in methods:\n",
    "            color = method_palette.get(method, 'gray')\n",
    "            \n",
    "            for i, prot_miss in enumerate(protein_levels):\n",
    "                method_data = sim2_summary[(sim2_summary['Method'] == method) & \n",
    "                                          (sim2_summary['Benchmark'] == benchmark) &\n",
    "                                          (sim2_summary['ProteinMissingness'] == prot_miss)]\n",
    "                \n",
    "                # Sort by peptide missingness\n",
    "                method_data = method_data.sort_values('PeptideMissingness')\n",
    "                \n",
    "                linestyle = ['-', '--', ':'][i]  # Different styles for different protein missingness\n",
    "                alpha = 1.0 if i == 0 else 0.7\n",
    "                linewidth = 2.5 if method == 'ProteoForge' else 2\n",
    "                \n",
    "                ax.plot(method_data['PeptideMissingness'] * 100, method_data['MCC'], \n",
    "                       color=color, linestyle=linestyle, marker='o', markersize=3,\n",
    "                       alpha=alpha, linewidth=linewidth)\n",
    "        \n",
    "        ax.set_title(benchmark, fontsize=10, fontweight='bold', pad=5)\n",
    "        if idx == 1:  # Only bottom plot gets x-axis label\n",
    "            ax.set_xlabel('Peptide Missingness (%)', fontsize=9)\n",
    "        ax.set_ylabel('MCC Score', fontsize=9)\n",
    "        ax.grid(True, linestyle=':', alpha=0.4)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_ylim(0, 0.85)\n",
    "    \n",
    "    # Create custom legend\n",
    "    legend_elements = []\n",
    "    for method in ['COPF', 'PeCorA', 'ProteoForge']:\n",
    "        color = method_palette.get(method, 'gray')\n",
    "        legend_elements.append(Line2D([0], [0], color=color, lw=2, label=method))\n",
    "    \n",
    "    # Add line style legend\n",
    "    legend_elements.extend([\n",
    "        Line2D([0], [0], color='gray', linestyle='-', lw=1, label='Protein 0%'),\n",
    "        Line2D([0], [0], color='gray', linestyle='--', lw=1, label='Protein 40%'),\n",
    "        Line2D([0], [0], color='gray', linestyle=':', lw=1, label='Protein 80%')\n",
    "    ])\n",
    "    \n",
    "    fig.legend(handles=legend_elements, loc='lower center', ncol=3, \n",
    "              bbox_to_anchor=(0.5, -0.05), fontsize=8, frameon=False)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "    return fig\n",
    "\n",
    "create_degradation_lines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747baa59",
   "metadata": {},
   "source": [
    "**Assessment:** Shows interaction between protein and peptide missingness, easy to spot the most obvious point, however not clean and details such as the protein level missingness is hard to read.\n",
    "\n",
    "#### Visualization Option 2: Compact Line Plot with Change Annotations *(Selected)*\n",
    "\n",
    "Shows MCC at diagonal missingness levels (Complete → Low → Moderate → High → Extreme) with Δ annotations, calculated from Complete - Others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e496a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(5, 5), sharex=True)\n",
    "fig.suptitle('Performance Change Across Missingness Levels', fontsize=12, fontweight='bold')\n",
    "\n",
    "benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "method_sets = {\n",
    "    'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "    'Peptide Grouping': ['COPF', 'ProteoForge']\n",
    "}\n",
    "\n",
    "change_levels = [\n",
    "    ('Complete\\n(0%,0%)', 0.0, 0.0),\n",
    "    ('Low\\n(20%,20%)', 0.2, 0.2),\n",
    "    ('Moderate\\n(40%,40%)', 0.4, 0.4),\n",
    "    ('High\\n(60%,60%)', 0.6, 0.6),\n",
    "    ('Extreme\\n(80%,80%)', 0.8, 0.8)\n",
    "]\n",
    "change_labels = [x[0] for x in change_levels]\n",
    "\n",
    "for idx, benchmark in enumerate(benchmarks):\n",
    "    ax = axs[idx]\n",
    "    methods = method_sets[benchmark]\n",
    "    for method in methods:\n",
    "        color = method_palette.get(method, 'gray')\n",
    "        marker = method_markers.get(method, 'o')\n",
    "        mcc_vals = []\n",
    "        for _, prot_miss, pep_miss in change_levels:\n",
    "            mcc_val = sim2_summary[(sim2_summary['Method'] == method) &\n",
    "                                   (sim2_summary['Benchmark'] == benchmark) &\n",
    "                                   (sim2_summary['ProteinMissingness'] == prot_miss) &\n",
    "                                   (sim2_summary['PeptideMissingness'] == pep_miss)]['MCC'].values\n",
    "            mcc_vals.append(mcc_val[0] if len(mcc_val) > 0 else np.nan)\n",
    "        ax.plot(change_labels, mcc_vals, color=color, marker=marker, markersize=8, linewidth=2.5,\n",
    "                label=method, alpha=0.9, markeredgecolor='black', markeredgewidth=1.5)\n",
    "        # Annotate difference from Complete\n",
    "        for i in range(1, len(mcc_vals)):\n",
    "            if not np.isnan(mcc_vals[0]) and not np.isnan(mcc_vals[i]):\n",
    "                diff = mcc_vals[i] - mcc_vals[0]\n",
    "                arrow = '↑' if diff > 0 else '↓'\n",
    "                color_diff = 'green' if diff > 0 else 'red'\n",
    "                ax.text(change_labels[i], mcc_vals[i] + 0.03, f'{arrow}{abs(diff):.2f}',\n",
    "                        ha='center', va='bottom', fontsize=8, color=color_diff, fontweight='bold')\n",
    "        # Annotate the complete MCC value\n",
    "        if not np.isnan(mcc_vals[0]):\n",
    "            ax.text(change_labels[0], mcc_vals[0] - 0.04, f'{mcc_vals[0]:.2f}',\n",
    "                    ha='center', va='top', fontsize=8, color=color, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor=color, alpha=0.7))\n",
    "    ax.set_title(benchmark, fontsize=10, fontweight='bold', pad=5)\n",
    "    ax.set_ylabel('MCC Score', fontsize=9)\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.4)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_ylim(-.15, 0.75)\n",
    "\n",
    "axs[-1].set_xlabel('Missingness Level (Protein%, Peptide%)', fontsize=9)\n",
    "axs[-1].set_xticks(change_labels)\n",
    "axs[-1].set_xticklabels(change_labels, fontsize=9)\n",
    "\n",
    "# Unified legend\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.08), fontsize=9, frameon=False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "plt.show()\n",
    "plots.finalize_plot(\n",
    "    fig, show=True, save=save_to_folder,\n",
    "    filename='benchmark_sim2_missingness_effect',\n",
    "    filepath=figure_path,\n",
    "    formats=figure_formats, \n",
    "    transparent=transparent_bg,\n",
    "    dpi=figure_dpi,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb98d2",
   "metadata": {},
   "source": [
    "**Assessment:** Clearly shows degradation trend; annotations highlight performance loss magnitude.\n",
    "\n",
    "#### Visualization Option 3: Performance Ratio Bars\n",
    "\n",
    "Shows MCC retention relative to complete data baseline (ratio = 1.0 means no performance loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf405ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_ratios(figsize=(5, 5)):\n",
    "    \"\"\"Show performance relative to complete data (0%,0%) as compact bars - Vertical Layout\"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "    fig.suptitle('Performance Relative to Complete Data', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "    method_sets = {\n",
    "        'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "        'Peptide Grouping': ['COPF', 'ProteoForge']  # No PeCorA for grouping\n",
    "    }\n",
    "    \n",
    "    # Key impaired scenarios relative to complete\n",
    "    scenarios = [\n",
    "        (0.2, 0.2, 'Low\\n(20%,20%)'),\n",
    "        (0.4, 0.4, 'Moderate\\n(40%,40%)'),\n",
    "        (0.6, 0.6, 'High\\n(60%,60%)'),\n",
    "        (0.8, 0.8, 'Severe\\n(80%,80%)')\n",
    "    ]\n",
    "    \n",
    "    for idx, benchmark in enumerate(benchmarks):\n",
    "        ax = axs[idx]\n",
    "        methods = method_sets[benchmark]\n",
    "        \n",
    "        # Get baseline performance (complete data)\n",
    "        baseline_mcc = {}\n",
    "        for method in methods:\n",
    "            baseline_data = sim2_summary[(sim2_summary['Method'] == method) & \n",
    "                                        (sim2_summary['Benchmark'] == benchmark) &\n",
    "                                        (sim2_summary['ProteinMissingness'] == 0.0) &\n",
    "                                        (sim2_summary['PeptideMissingness'] == 0.0)]\n",
    "            if len(baseline_data) > 0:\n",
    "                baseline_mcc[method] = baseline_data['MCC'].values[0]\n",
    "        \n",
    "        x_pos = np.arange(len(scenarios))\n",
    "        width = 0.8 / len(methods)\n",
    "        \n",
    "        for i, method in enumerate(methods):\n",
    "            if method not in baseline_mcc:\n",
    "                continue\n",
    "                \n",
    "            color = method_palette.get(method, 'gray')\n",
    "            ratios = []\n",
    "            \n",
    "            for prot_miss, pep_miss, label in scenarios:\n",
    "                impaired_data = sim2_summary[(sim2_summary['Method'] == method) & \n",
    "                                           (sim2_summary['Benchmark'] == benchmark) &\n",
    "                                           (sim2_summary['ProteinMissingness'] == prot_miss) &\n",
    "                                           (sim2_summary['PeptideMissingness'] == pep_miss)]\n",
    "                \n",
    "                if len(impaired_data) > 0:\n",
    "                    impaired_val = impaired_data['MCC'].values[0]\n",
    "                    # Calculate ratio (performance retention)\n",
    "                    ratio = impaired_val / baseline_mcc[method] if baseline_mcc[method] > 0 else 0\n",
    "                    ratios.append(ratio)\n",
    "                else:\n",
    "                    ratios.append(0)\n",
    "            \n",
    "            # Plot bars\n",
    "            x_offset = x_pos + (i - len(methods)/2 + 0.5) * width\n",
    "            bars = ax.bar(x_offset, ratios, width, color=color, alpha=0.8, \n",
    "                         edgecolor='black', linewidth=0.5,\n",
    "                         label=method if idx == 0 else \"\")\n",
    "            \n",
    "            # Add ratio text on bars\n",
    "            for bar, ratio in zip(bars, ratios):\n",
    "                if ratio > 0:\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                           f'{ratio:.2f}', ha='center', va='bottom', fontsize=7, fontweight='bold')\n",
    "        \n",
    "        # Add reference line at 1.0 (no performance loss)\n",
    "        ax.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        ax.set_title(benchmark, fontsize=10, fontweight='bold', pad=5)\n",
    "        if idx == 1:  # Only bottom plot gets x-axis labels\n",
    "            ax.set_xticks(x_pos)\n",
    "            ax.set_xticklabels([s[2] for s in scenarios], fontsize=8)\n",
    "        else:\n",
    "            ax.set_xticks(x_pos)\n",
    "            ax.set_xticklabels([])\n",
    "        ax.set_ylabel('Performance Ratio', fontsize=9)\n",
    "        ax.grid(axis='y', linestyle=':', alpha=0.4)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_ylim(0, 1.3)\n",
    "    \n",
    "    # Legend and annotations\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=3, \n",
    "              bbox_to_anchor=(0.5, -0.05), fontsize=9, frameon=False)\n",
    "    \n",
    "    fig.text(0.02, 0.95, '1.0 = No performance loss', fontsize=7, \n",
    "             color='red', style='italic', transform=fig.transFigure)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.08, 1, 0.92])\n",
    "    return fig\n",
    "\n",
    "create_performance_ratios()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643609df",
   "metadata": {},
   "source": [
    "**Assessment:** Clearly shows degradation trend, however the Ratio gives advantage to COPF where it looks it doesn't get effected by missingness even in extreme levels. While this is true at face value, it is misleading as COPF's absolute performance is already low, so the ratio exaggerates its stability.\n",
    "\n",
    "**Key Findings — Simulation 2:**\n",
    "- Peptide Identification: \n",
    "    - Performance degrades progressively with increasing missingness\n",
    "    - Methods maintain reasonable accuracy (~70% retention) up to 40% missingness\n",
    "    - ProteoForge shows minimal effect until 80% Severe missingness, but even then drops 0.80 \n",
    "    - Beyond 60% missingness, detection reliability decreases substantially\n",
    "- Peptide Grouping:\n",
    "    - Peptide grouping improves slightly with low to moderate missingness for ProteoForge\n",
    "    - COPF also shows it shows that it gets down by .85-75 at all levels, meaning the amount of missingness doesn't matter much.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Simulation 3: Detection Sensitivity vs. Perturbation Magnitude\n",
    "\n",
    "**Objective:** Determine the minimum perturbation magnitude required for reliable detection.\n",
    "\n",
    "**Design:** Perturbation magnitudes ranging from subtle (0.10–0.25 log2) to strong (1.75–2.00 log2) with complete data (no missing values).\n",
    "\n",
    "**Key Questions:**\n",
    "- What is the practical detection threshold for each method?\n",
    "- How does sensitivity scale with perturbation size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfae33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore Sim3 data (Magnitude of perturbation levels)\n",
    "sim3_pepid = pd.read_feather('./data/Sim3/4_Sim3_PeptideIdentification_PerformanceData.feather')\n",
    "sim3_pepid['Benchmark'] = 'Peptide Identification'\n",
    "sim3_pepgrp = pd.read_feather('./data/Sim3/4_Sim3_Grouping_PerformanceData.feather')\n",
    "sim3_pepgrp['Benchmark'] = 'Peptide Grouping'\n",
    "sim3_combined = pd.concat([sim3_pepid, sim3_pepgrp], ignore_index=True)\n",
    "# sim3_combined\n",
    "\n",
    "pert_ranges = sorted(sim3_combined['PerturbationRange'].unique())\n",
    "\n",
    "# Process sim3 data for visualization\n",
    "def process_sim3_data():\n",
    "    \"\"\"Process sim3 data and normalize perturbation ranges\"\"\"\n",
    "    \n",
    "    # Create a copy to work with\n",
    "    sim3_processed = sim3_combined.copy()\n",
    "    \n",
    "    # Normalize perturbation range formatting and create magnitude column\n",
    "    def extract_magnitude(pert_range):\n",
    "        \"\"\"Extract average magnitude from perturbation range string\"\"\"\n",
    "        if isinstance(pert_range, str) and '-' in pert_range:\n",
    "            try:\n",
    "                start, end = pert_range.split('-')\n",
    "                return (float(start) + float(end)) / 2\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    sim3_processed['Magnitude'] = sim3_processed['PerturbationRange'].apply(extract_magnitude)\n",
    "    \n",
    "    # Normalize perturbation range names (handle 0.1 vs 0.10 inconsistency)\n",
    "    def normalize_range(pert_range):\n",
    "        if isinstance(pert_range, str) and '-' in pert_range:\n",
    "            try:\n",
    "                start, end = pert_range.split('-')\n",
    "                start_f = float(start)\n",
    "                end_f = float(end)\n",
    "                return f\"{start_f:.2f}-{end_f:.2f}\"\n",
    "            except:\n",
    "                return pert_range\n",
    "        return pert_range\n",
    "    \n",
    "    sim3_processed['PerturbationRange_norm'] = sim3_processed['PerturbationRange'].apply(normalize_range)\n",
    "    \n",
    "    # Get best MCC for each combination (since there are multiple thresholds)\n",
    "    sim3_summary = sim3_processed.groupby(['Method', 'Benchmark', 'PerturbationRange_norm', 'Magnitude'])['MCC'].mean().reset_index()\n",
    "    \n",
    "    # Sort by magnitude for proper ordering\n",
    "    sim3_summary = sim3_summary.sort_values('Magnitude')\n",
    "    \n",
    "    print(\"Processed sim3 summary:\")\n",
    "    print(f\"Shape: {sim3_summary.shape}\")\n",
    "    print(f\"Magnitude levels: {sorted(sim3_summary['Magnitude'].unique())}\")\n",
    "    print(f\"Perturbation ranges: {sorted(sim3_summary['PerturbationRange_norm'].unique())}\")\n",
    "    \n",
    "    return sim3_summary\n",
    "\n",
    "sim3_summary = process_sim3_data()\n",
    "sim3_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1a0bf",
   "metadata": {},
   "source": [
    "#### Visualization Option 1: Detection Curves with Endpoint Annotations *(Selected)*\n",
    "\n",
    "MCC vs. perturbation magnitude with method-specific trajectories and Δ(MCC) summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detection_curves_combined(figsize=(3.2, 6)):\n",
    "    \"\"\"Stylized detection curves with distribution-of-change summaries to the right.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    fig.suptitle('Perturbation Detection Sensitivity', fontsize=11, fontweight='bold', y=0.98)\n",
    "\n",
    "    # Ensure sim3_combined has a Magnitude column (average of perturbation range endpoints)\n",
    "    sim3_full = sim3_combined.copy()\n",
    "    def _extract_mag(pert):\n",
    "        if isinstance(pert, str) and ('-' in pert):\n",
    "            try:\n",
    "                a, b = pert.split('-')\n",
    "                return (float(a) + float(b)) / 2.0\n",
    "            except:\n",
    "                return np.nan\n",
    "        return np.nan\n",
    "    if 'Magnitude' not in sim3_full.columns:\n",
    "        sim3_full['Magnitude'] = sim3_full['PerturbationRange'].apply(_extract_mag)\n",
    "\n",
    "    benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "    method_sets = {\n",
    "        'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "        'Peptide Grouping': ['COPF', 'ProteoForge']\n",
    "    }\n",
    "    linestyle_map = {\n",
    "        'Peptide Identification': '-',\n",
    "        'Peptide Grouping': '--'\n",
    "    }\n",
    "\n",
    "    # Plot curves\n",
    "    plotted_info = []  # collect info for summary plotting (method, benchmark, first_mag, last_mag)\n",
    "    for benchmark in benchmarks:\n",
    "        methods = method_sets[benchmark]\n",
    "        for method in methods:\n",
    "            method_data = sim3_summary[\n",
    "                (sim3_summary['Method'] == method) & \n",
    "                (sim3_summary['Benchmark'] == benchmark)\n",
    "            ].sort_values('Magnitude')\n",
    "            if len(method_data) > 0:\n",
    "                color = method_palette.get(method, 'black')\n",
    "                marker = method_markers.get(method, 'o')\n",
    "                ls = linestyle_map[benchmark]\n",
    "                ax.plot(\n",
    "                    method_data['Magnitude'], method_data['MCC'],\n",
    "                    linestyle=ls, color=color, linewidth=2.5,\n",
    "                    marker=marker, markersize=7, alpha=0.9,\n",
    "                    markerfacecolor=color, markeredgecolor='black'\n",
    "                )\n",
    "\n",
    "                mag_vals = method_data['Magnitude'].values\n",
    "                mcc_vals = method_data['MCC'].values\n",
    "\n",
    "                # Directly label at the end of the curve\n",
    "                label_text = \"ID\" if benchmark == \"Peptide Identification\" else \"Group\"\n",
    "                ax.text(\n",
    "                    mag_vals[-1] + 0.03, mcc_vals[-1],\n",
    "                    f\"{label_text}\",\n",
    "                    ha='left', va='center', fontsize=8, fontweight='bold',\n",
    "                    color=color, bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8)\n",
    "                )\n",
    "\n",
    "                plotted_info.append({\n",
    "                    'method': method,\n",
    "                    'benchmark': benchmark,\n",
    "                    'first_mag': mag_vals[0],\n",
    "                    'last_mag': mag_vals[-1],\n",
    "                    'color': color\n",
    "                })\n",
    "\n",
    "    ax.set_xlabel('Mean Perturbation Magnitude (log2)', fontsize=9)\n",
    "    ax.set_ylabel('MCC Score', fontsize=10)\n",
    "    ax.set_xlim(0.1, 2.0)\n",
    "    ax.set_ylim(-0.05, 0.85)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    mag_ticks = [0.2, 0.6, 1.0, 1.4, 1.8]\n",
    "    ax.set_xticks(mag_ticks)\n",
    "    ax.set_xticklabels([str(x) for x in mag_ticks], fontsize=8)\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "    # --- Summary to the right: vertical lines with annotation spanning MCC change ---\n",
    "    if len(plotted_info) > 0:\n",
    "        max_mag = sim3_summary['Magnitude'].max()\n",
    "        x_base = max_mag + 0.08\n",
    "        # create small offsets so multiple methods don't overlap\n",
    "        max_methods = max(len(method_sets[b]) for b in benchmarks)\n",
    "        offsets = np.linspace(-0.06, 0.06, max_methods)\n",
    "\n",
    "        for bench_idx, benchmark in enumerate(benchmarks):\n",
    "            methods = method_sets[benchmark]\n",
    "            for m_idx, method in enumerate(methods):\n",
    "                info = next((it for it in plotted_info if it['method'] == method and it['benchmark'] == benchmark), None)\n",
    "                if info is None:\n",
    "                    continue\n",
    "\n",
    "                first_mag = info['first_mag']\n",
    "                last_mag = info['last_mag']\n",
    "                color = info['color']\n",
    "\n",
    "                # Get MCC at first and last magnitude\n",
    "                mrow_first = sim3_summary[\n",
    "                    (sim3_summary['Method'] == method) &\n",
    "                    (sim3_summary['Benchmark'] == benchmark) &\n",
    "                    (sim3_summary['Magnitude'] == first_mag)\n",
    "                ]\n",
    "                mrow_last = sim3_summary[\n",
    "                    (sim3_summary['Method'] == method) &\n",
    "                    (sim3_summary['Benchmark'] == benchmark) &\n",
    "                    (sim3_summary['Magnitude'] == last_mag)\n",
    "                ]\n",
    "                if len(mrow_first) > 0 and len(mrow_last) > 0:\n",
    "                    mcc_first = mrow_first['MCC'].median()\n",
    "                    mcc_last = mrow_last['MCC'].median()\n",
    "                    median_diff = mcc_last - mcc_first\n",
    "                    norm_diff = median_diff / (abs(mcc_first) + 1e-6)\n",
    "\n",
    "                    x_pos = x_base + offsets[m_idx]\n",
    "                    # Draw vertical line spanning MCC range\n",
    "                    ax.plot([x_pos, x_pos], [mcc_first, mcc_last], color=color, linewidth=2.5, alpha=0.8, linestyle=linestyle_map[benchmark])\n",
    "                    # Annotate at midpoint\n",
    "                    mid_y = (mcc_first + mcc_last) / 2\n",
    "                    txt = (f\"Δ={median_diff:.3f}\")\n",
    "                    ax.text(x_pos + 0.03, mid_y, txt, fontsize=7, va='center', ha='left',\n",
    "                            color=color, bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "        # expand x-limits to accommodate the summaries\n",
    "        ax.set_xlim(ax.get_xlim()[0], x_base + 0.18)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = create_detection_curves_combined(figsize=(5, 6))\n",
    "plt.show()\n",
    "plots.finalize_plot(\n",
    "    fig, show=True, save=save_to_folder,\n",
    "    filename='benchmark_sim3_perturbation_detection',\n",
    "    filepath=figure_path,\n",
    "    formats=figure_formats, \n",
    "    transparent=transparent_bg,\n",
    "    dpi=figure_dpi,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbaca5",
   "metadata": {},
   "source": [
    "**Assessment:** Comprehensive view of sensitivity curves; endpoint Δ annotations aid interpretation. \n",
    "\n",
    "#### Visualization Option 2: Detection Efficiency Bars\n",
    "\n",
    "Compact comparison at categorical magnitude levels (Low → Mid-Low → Mid-High → High)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIM3 Compact Visualization Approach 3: Detection Efficiency Bar Chart (VERTICAL)\n",
    "def create_detection_efficiency_bars(figsize=(5, 4)):\n",
    "    \"\"\"Show detection efficiency at key perturbation levels\"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "    fig.suptitle('Detection Efficiency at Key Perturbation Levels', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Select key perturbation levels for comparison\n",
    "    key_magnitudes = [0.175, 0.625, 1.125, 1.875]  # Low, Mid-low, Mid-high, High\n",
    "    mag_labels = ['Low\\n(~0.2)', 'Mid-Low\\n(~0.6)', 'Mid-High\\n(~1.1)', 'High\\n(~1.9)']\n",
    "    \n",
    "    benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "    method_sets = {\n",
    "        'Peptide Identification': ['COPF', 'PeCorA', 'ProteoForge'],\n",
    "        'Peptide Grouping': ['COPF', 'ProteoForge']\n",
    "    }\n",
    "    \n",
    "    for i, benchmark in enumerate(benchmarks):\n",
    "        ax = axs[i]\n",
    "        methods = method_sets[benchmark]\n",
    "        \n",
    "        # Prepare data for bar chart\n",
    "        x_positions = np.arange(len(key_magnitudes))\n",
    "        width = 0.8 / len(methods)\n",
    "        \n",
    "        for m_idx, method in enumerate(methods):\n",
    "            method_scores = []\n",
    "            \n",
    "            for magnitude in key_magnitudes:\n",
    "                method_data = sim3_summary[\n",
    "                    (sim3_summary['Method'] == method) & \n",
    "                    (sim3_summary['Benchmark'] == benchmark) &\n",
    "                    (sim3_summary['Magnitude'] == magnitude)\n",
    "                ]\n",
    "                \n",
    "                if len(method_data) > 0:\n",
    "                    method_scores.append(method_data['MCC'].iloc[0])\n",
    "                else:\n",
    "                    method_scores.append(0)\n",
    "            \n",
    "            # Plot bars\n",
    "            color = method_palette.get(method, 'black')\n",
    "            x_pos = x_positions + (m_idx - len(methods)/2 + 0.5) * width\n",
    "            \n",
    "            bars = ax.bar(x_pos, method_scores, width, \n",
    "                         color=color, alpha=0.8, label=method,\n",
    "                         edgecolor='white', linewidth=0.5)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, score in zip(bars, method_scores):\n",
    "                if score > 0.05:  # Only show if meaningful\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                           f'{score:.2f}', ha='center', va='bottom', \n",
    "                           fontsize=6, fontweight='bold', color=color)\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_title(benchmark, fontsize=10, fontweight='bold', loc='left')\n",
    "        ax.set_ylabel('MCC Score', fontsize=9)\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.set_xticks(x_positions)\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)\n",
    "        \n",
    "        if i == 1:  # Bottom plot\n",
    "            ax.set_xlabel('Perturbation Magnitude Level', fontsize=9)\n",
    "            ax.set_xticklabels(mag_labels, fontsize=8)\n",
    "        else:\n",
    "            ax.set_xticklabels([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "create_detection_efficiency_bars()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b2868",
   "metadata": {},
   "source": [
    "**Key Findings — Simulation 3:**\n",
    "- MCC increases monotonically with perturbation magnitude across all methods\n",
    "- Practical detection threshold: ~0.5 log2 (MCC improves sharply above this level)\n",
    "- ProteoForge shows strong sensitivity for the Peptide Identification benchmark\n",
    "- Methods converge at high magnitudes—differences are most pronounced for subtle perturbations\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 Simulation 4: Complex Multi-Variable Experimental Designs\n",
    "\n",
    "**Objective:** Evaluate method robustness across experimental designs with multiple interacting factors.\n",
    "\n",
    "**Design Factors:**\n",
    "- **Number of conditions**: 2, 4, 6, or 8 experimental groups\n",
    "- **Overlap pattern**: Same peptides perturbed across conditions (True) vs. different peptides (False)\n",
    "- **Direction**: All perturbations in same direction vs. random up/down changes\n",
    "\n",
    "**Key Questions:**\n",
    "- Does adding more experimental conditions improve detection?\n",
    "- Which perturbation patterns are easier to detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore Sim3 data (Magnitude of perturbation levels)\n",
    "sim4_pepid = pd.read_feather('./data/Sim4/4_Sim4_PeptideIdentification_PerformanceData.feather')\n",
    "sim4_pepid['Benchmark'] = 'Peptide Identification'\n",
    "sim4_pepgrp = pd.read_feather('./data/Sim4/4_Sim4_Grouping_PerformanceData.feather')\n",
    "sim4_pepgrp['Benchmark'] = 'Peptide Grouping'\n",
    "sim4_combined = pd.concat([sim4_pepid, sim4_pepgrp], ignore_index=True)\n",
    "\n",
    "sim4_summary = sim4_combined.groupby([\n",
    "        'Method', 'Benchmark', 'Overlap', 'Direction', 'N_Conditions'\n",
    "    ])['MCC'].mean().unstack().reset_index()\n",
    "# sim4_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73bc2f",
   "metadata": {},
   "source": [
    "#### Robustness Across Experimental Setups\n",
    "\n",
    "Line plots showing MCC vs. number of conditions, with line styles encoding overlap (solid=True, dashed=False) and markers encoding direction (●=random, ■=same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7577a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(5.0, 5.0), sharex=True)\n",
    "fig.suptitle('Method Robustness Across Experimental Setups', fontsize=10, fontweight='bold', y=0.98)\n",
    "\n",
    "# Aggregate\n",
    "agg = sim4_combined.groupby(['Benchmark','Method','Overlap','Direction','N_Conditions'])['MCC'].mean().reset_index()\n",
    "\n",
    "# Order methods by overall mean performance so best are drawn last (on top)\n",
    "method_order = agg.groupby('Method')['MCC'].mean().sort_values(ascending=True).index.tolist()\n",
    "\n",
    "benchmarks = ['Peptide Identification', 'Peptide Grouping']\n",
    "direction_marker = {'random': 'o', 'same': 's'}\n",
    "overlap_ls = {True: '-', False: '--'}\n",
    "\n",
    "# Plot each benchmark in its own small panel\n",
    "for i, benchmark in enumerate(benchmarks):\n",
    "    ax = axes[i]\n",
    "    sub = agg[agg['Benchmark'] == benchmark].copy()\n",
    "    # draw in method order so higher performers are on top\n",
    "    for method in method_order:\n",
    "        sub_m = sub[sub['Method'] == method]\n",
    "        if sub_m.empty:\n",
    "            continue\n",
    "        # within method, draw combinations of overlap/direction\n",
    "        combos = sorted(sub_m.groupby(['Overlap','Direction']), key=lambda x: (x[0][0], x[0][1]))\n",
    "        for (overlap, direction), grp in combos:\n",
    "            grp = grp.sort_values('N_Conditions')\n",
    "            color = method_palette.get(method, '#333333')\n",
    "            ls = overlap_ls.get(overlap, '-')\n",
    "            mk = direction_marker.get(direction, 'o')\n",
    "            # Plot line with clearly visible marker edge for small sizes\n",
    "            ax.plot(\n",
    "                grp['N_Conditions'], grp['MCC'],\n",
    "                color=color, linestyle=ls, marker=mk,\n",
    "                markersize=5, markeredgecolor='black', markeredgewidth=0.7,\n",
    "                linewidth=1.6, alpha=0.95, zorder=3\n",
    "            )\n",
    "            # small endpoint label (method short) to aid reading in compact panel\n",
    "            last_x = grp['N_Conditions'].iloc[-1]\n",
    "            last_y = grp['MCC'].iloc[-1]\n",
    "            ax.text(\n",
    "                last_x + 0.12, last_y,\n",
    "                method if (overlap, direction) == (True, 'random') else \"\",\n",
    "                fontsize=10, fontweight='bold', color=color, va='center'\n",
    "            )\n",
    "\n",
    "    # Styling for compact embedding\n",
    "    ax.set_title(benchmark, fontsize=9, fontweight='bold', loc='left')\n",
    "    ax.set_ylabel('MCC', fontsize=8)\n",
    "    ax.set_ylim(-0.05, 0.88)\n",
    "    ax.grid(axis='y', linestyle=':', linewidth=0.6, alpha=0.5)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    # # Panel label (A / B) for later placement in multi-panel figures\n",
    "    # panel_label = 'A' if i == 0 else 'B'\n",
    "    # ax.text(0.01, 0.98, panel_label, transform=ax.transAxes,\n",
    "    #         fontsize=9, fontweight='bold', va='top', ha='left',\n",
    "    #         bbox=dict(boxstyle='round,pad=0.15', facecolor='white', edgecolor='none', alpha=0.8))\n",
    "\n",
    "# X-axis formatting (shared)\n",
    "unique_conds = sorted(agg['N_Conditions'].unique())\n",
    "axes[-1].set_xticks(unique_conds)\n",
    "axes[-1].set_xlabel('Number of Conditions', fontsize=8)\n",
    "axes[-1].tick_params(axis='x', labelsize=7)\n",
    "\n",
    "# Build compact legends (method color, overlap linestyle, direction marker)\n",
    "methods_present = [m for m in method_order if m in agg['Method'].unique()]\n",
    "method_handles = [\n",
    "    Line2D([0], [0], color=method_palette.get(m, 'gray'), lw=2.5, label=m)\n",
    "    for m in methods_present\n",
    "]\n",
    "overlap_handles = [\n",
    "    Line2D([0], [0], color='gray', lw=1.8, linestyle='-', label='Overlap: True'),\n",
    "    Line2D([0], [0], color='gray', lw=1.8, linestyle='--', label='Overlap: False'),\n",
    "]\n",
    "direction_handles = [\n",
    "    Line2D([0], [0], color='black', marker='o', linestyle='None', markersize=5, label='Direction: random'),\n",
    "    Line2D([0], [0], color='black', marker='s', linestyle='None', markersize=5, label='Direction: same'),\n",
    "]\n",
    "\n",
    "# # Place method legend in top-left of first panel and style legend for patterns in second\n",
    "# leg1 = axes[0].legend(handles=method_handles, title='Method', loc='upper left',\n",
    "#                       fontsize=7, title_fontsize=8, frameon=False, ncol=1)\n",
    "# axes[0].add_artist(leg1)\n",
    "axes[1].legend(handles=overlap_handles + direction_handles, loc='upper left',\n",
    "               fontsize=7, frameon=False, ncol=1)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "plots.finalize_plot(\n",
    "    fig, show=True, save=save_to_folder,\n",
    "    filename='benchmark_sim4_experimental_setups',\n",
    "    filepath=figure_path,\n",
    "    formats=figure_formats, \n",
    "    transparent=transparent_bg,\n",
    "    dpi=figure_dpi,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca2768",
   "metadata": {},
   "source": [
    "**Key Findings — Simulation 4:**\n",
    "- Higher number of conditions help with peptide identification for linear model based methods like PeCorA and ProteoForge\n",
    "- When it comes to peptide identification the pattern accross different setups for PeCorA and ProteoForge is extremely similar just with different MCC levels due to the data being missing/imputed version.\n",
    "- Allowing overlap seems to improve the performance, likely resulting in less predicted groups of peptides, making it easier to identify them correctly.\n",
    "- Direction of the perturbations (same vs. random) has less effect than other factors\n",
    "- ProteoForge consistently outperforms other methods across design configurations\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Figure Assembly\n",
    "\n",
    "### Generated Figure Panels\n",
    "\n",
    "| Panel | Source | Description | File |\n",
    "|-------|--------|-------------|------|\n",
    "| **2A-B** | SWATH-MS | MCC barplots: Identification & Grouping | `benchmark_compact_fig2ab.pdf` |\n",
    "| **2C** | Sim1 | Imputation impact (vertical bars) | `benchmark_sim1_imputation_effect.pdf` |\n",
    "| **2D** | Sim2 | Missingness degradation (line plot) | `benchmark_sim2_missingness_effect.pdf` |\n",
    "| **2E** | Sim3 | Detection sensitivity curves | `benchmark_sim3_perturbation_detection.pdf` |\n",
    "| **2F** | Sim4 | Experimental design robustness | `benchmark_sim4_experimental_setups.pdf` |\n",
    "\n",
    "### Summary of Benchmark Findings\n",
    "\n",
    "1. **Real-world performance (SWATH-MS):** ProteoForge achieves competitive MCC across perturbation scenarios, with strongest relative performance in identification tasks.\n",
    "\n",
    "2. **Imputation robustness (Sim1):** ProteoForge has minimal performance impact from imputated and robust to appropriately handled missing values.\n",
    "\n",
    "3. **Missingness tolerance (Sim2):** ~40% missingness threshold before substantial degradation; all methods show similar sensitivity patterns.\n",
    "\n",
    "4. **Detection sensitivity (Sim3):** ~0.5 log2 perturbation magnitude marks the practical detection threshold; larger effects are consistently detected.\n",
    "\n",
    "5. **Design complexity (Sim4):** More conditions improve detection; overlapping perturbation patterns offer detection advantages.\n",
    "\n",
    "> **Note:** Figures exported as PDF vectors for final assembly in Inkscape. Panel labels and minor styling adjustments to be applied during composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook Execution Time:\", utils.prettyTimer(utils.getTime() - startTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
