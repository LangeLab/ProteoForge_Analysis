{
 "cells": [
  {
   "cell_type": "raw",
   "id": "253544ee",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "title: Notebook S4\n",
    "author: Enes Kemal Ergin\n",
    "date: \"{{ datetime.now().strftime('%Y-%m-%d %H:%M:%S') }}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba62424",
   "metadata": {},
   "source": [
    "# Supplementary Notebook S4: Generating Simulation Datasets for Benchmarking\n",
    "\n",
    "- **License:** [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/)\n",
    "- **Version:** 0.1\n",
    "- **Edit Log:** \n",
    "    - 2025-11-28: Initial version of the notebook\n",
    "\n",
    "---\n",
    "\n",
    "**Requirements:**  \n",
    "\n",
    "This notebook doesn't need any data requirements as it generates synthetic datasets from scratch.\n",
    "\n",
    "**Data Information:**  \n",
    "This notebook generates synthetic proteomics datasets from scratch—no input files required. All simulated data is saved to `./data/Sim{1-4}/` folders as Feather files.\n",
    "\n",
    "**Purpose:**  \n",
    "Generate controlled synthetic proteomics datasets to benchmark proteoform detection methods (COPF, PeCorA, ProteoForge) under systematically varied conditions. Four simulation scenarios are created:\n",
    "\n",
    "| Simulation | Focus | Variations |\n",
    "|------------|-------|------------|\n",
    "| **Sim1** | Imputation effects | 4 perturbation patterns × 2 data types (complete/imputed) |\n",
    "| **Sim2** | Missingness tolerance | 5 protein × 5 peptide missingness levels = 25 combinations |\n",
    "| **Sim3** | Detection sensitivity | 8 perturbation magnitude ranges |\n",
    "| **Sim4** | Experimental complexity | 5 conditions × 2 overlap × 2 direction = 20 combinations |\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "This section imports libraries, configures display settings, and defines paths for outputs.\n",
    "\n",
    "> **Note:** The HTML rendering of this notebook hides code cells by default. Click the \"Code\" buttons to expand them.\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c41bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np # Numerical computing\n",
    "import pandas as pd # Data manipulatio\n",
    "\n",
    "import seaborn as sns # R-like high-level plots\n",
    "import matplotlib.pyplot as plt # Python's base plotting \n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "# Utility imports for this analysis\n",
    "from src import utils, plots\n",
    "\n",
    "from Simulation import sims # Simulation functions \n",
    "\n",
    "# Initialize the timer\n",
    "startTime = utils.getTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49208e51",
   "metadata": {},
   "source": [
    "### Display Settings\n",
    "\n",
    "The cell below configures pandas, matplotlib, and seaborn display options for improved readability of tables and figures, including color palettes and figure export settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48520e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Figure Settings\n",
    "\n",
    "# Define default colors and styles for plots\n",
    "def_colors = [\n",
    "    \"#139593\", \"#fca311\", \"#e54f2a\",\n",
    "    \"#c3c3c3\", \"#555555\",\n",
    "    \"#690000\", \"#5f4a00\", \"#004549\"\n",
    "]\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_theme(\n",
    "    style=\"white\",\n",
    "    context=\"paper\",\n",
    "    palette=def_colors,\n",
    "    font_scale=1,\n",
    "    rc={\n",
    "        \"figure.figsize\": (6, 4),\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Arial\", \"Ubuntu Mono\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Figure Saving Settings\n",
    "figure_formats = [\"pdf\"]\n",
    "save_to_folder = True\n",
    "transparent_bg = True\n",
    "figure_dpi = 300\n",
    "\n",
    "## Configure dataframe displaying\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 500)  # Set a wider display width\n",
    "\n",
    "## Printing Settings\n",
    "verbose = True\n",
    "\n",
    "## Reproducibility Settings\n",
    "seed = 42\n",
    "\n",
    "## Show the color-palettes\n",
    "plots.color_palette( def_colors, save=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21278cd2",
   "metadata": {},
   "source": [
    "### Paths and Global Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Variables\n",
    "pThr = 10**-3\n",
    "cur_method = \"wls\"\n",
    "method_title = \"Weighted Least Squares\"\n",
    "formula = 'adjIntensity ~ Condition * allothers'\n",
    "thresholds = list(utils.generate_thresholds(10.0, -15, 1, 0, 1, 0.1))\n",
    "\n",
    "\n",
    "# Establish paths and \n",
    "notebook_name = \"01-SimulatedDatasets\"\n",
    "input_path = f\"./data/\"\n",
    "mainFig_path = f\"./figures/\"\n",
    "\n",
    "def setup_simulation_paths( simID ):\n",
    "    \"\"\"\n",
    "    Create output and figure directories for a simulation, if they do not exist. \n",
    "    (Uses global variable for save_to_folder and figure_formats)\n",
    "\n",
    "    Args:\n",
    "        simID (str): Simulation ID.\n",
    "        \n",
    "        (Global Variables)\n",
    "            input_path (str): Base path for input data.\n",
    "            mainFig_path (str): Base path for figures.\n",
    "            save_to_folder (bool): Whether to save figures to folders.\n",
    "            figure_formats (list): List of formats to save figures in.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (output_path, figure_path)\n",
    "    \"\"\"\n",
    "    output_path = f\"{input_path}{simID}/\"\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    figure_path = f\"{mainFig_path}{simID}/\"\n",
    "    if save_to_folder:\n",
    "        for fmt in figure_formats:\n",
    "            cur_folder = os.path.join(figure_path, fmt)\n",
    "            if not os.path.exists(cur_folder):\n",
    "                os.makedirs(cur_folder)\n",
    "    return output_path, figure_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b651c48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simulation 1: Complete vs. Imputed Data Comparison\n",
    "\n",
    "**Objective:** Assess whether imputing missing values affects method performance compared to complete (fully quantified) datasets.\n",
    "\n",
    "**Experimental Design:**\n",
    "- **Base dataset**: 500 proteins × 3 conditions × 10 replicates, 5–50 peptides per protein\n",
    "- **Perturbation**: 250 proteins perturbed in condition 2 with magnitude 0.5–1.5 log2\n",
    "- **Four perturbation patterns tested**:\n",
    "  1. **twoPep** — Exactly 2 peptides perturbed per protein\n",
    "  2. **halfPep** — 50% of peptides perturbed per protein\n",
    "  3. **halfPlusPep** — 70% of peptides perturbed per protein\n",
    "  4. **randomPep** — Random 10–50% of peptides perturbed per protein\n",
    "- **Data versions**: Each pattern generates both complete and imputed versions\n",
    "- **Imputation**: Downshifted imputation with 35% missingness rate\n",
    "\n",
    "**Output Files:** `./data/Sim1/2_{pattern}_{complete|imputed}_InputData.feather`\n",
    "\n",
    "### Base Dataset Generation\n",
    "\n",
    "The code below generates the foundational protein/peptide data structure used across all Sim1 perturbation scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54c5c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Simulation ID:     Sim1\n",
      "==================================================\n",
      "• Simulation Data:\n",
      "    - Generates a synthetic proteomics dataset with 500 proteins.\n",
      "    - Each protein has 5–50 peptides, across 3 conditions.\n",
      "    - The first condition is the control; the rest are experimental.\n",
      "• Simulation Goal:\n",
      "    - Compare the effects of perturbations on the data, both in complete and imputed forms.\n",
      "• Parameters:\n",
      "    - RNG seed: 42\n",
      "    - 3 conditions (control + 2 treatments), log2 shifts: [0, 1, 2]\n",
      "    - 500 proteins × 10 replicates, 5–50 peptides/protein\n",
      "    - Perturbing 250/500 proteins (overlap=False)\n",
      "    - Perturbation in conditions: ['cond2'], magnitude range: (0.5, 1.5)\n",
      "\n",
      "==================================================\n",
      "• Step 1: Generate Protein Mean Values (with outliers)\n",
      "    - Using seed: 42\n",
      "    - Generated 500 protein mean values (log2 scale)\n",
      "    - Stats: mean=20.01, std=1.96, min=13.52, max=27.71\n",
      "    - Outliers: fraction=10.0%, sd-multiplier=1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 2: Generate Protein Coefficient of Variation (CV) Values\n",
      "    - Log-normal distribution: mean=10, median=8\n",
      "    - Generated 500 CV values\n",
      "    - Stats: mean=10.07, std=8.36, min=0.92, max=104.93\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 3: Generate Replicates for Control (Biological Reference)\n",
      "    - Generated 10 control replicates for 500 proteins\n",
      "    - This subset will serve as the control for all treatments.\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 4: Generate Number of Peptides per Protein\n",
      "    - Beta-binomial: min=5, max=50, alpha=0.5, beta=3\n",
      "    - Generated 500 peptide counts\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 5: Generate Peptide-Level Data from Protein-Level Data\n",
      "    - Peptide-level data: 5583 peptides × 12 samples\n",
      "    - Noise: sd=0.10, Outliers: fraction=0.0001, multiplier=0.01\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 6: Generate Condition Mappers\n",
      "    - Condition sample map keys: ['control', 'cond1', 'cond2']\n",
      "    - Condition shifts: {'control': 0, 'cond1': 1, 'cond2': 2}\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 7: Generate Complete Peptide-Level Data for All Conditions\n",
      "    - Complete dataset: 5583 peptides × 30 samples\n",
      "    - Noise: sd=0.10, shift_scale=0.10, no additional noise added\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stTime = utils.getTime()\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "simID = \"Sim1\"\n",
    "seed = 42  # Seed for reproducibility\n",
    "n_condition = 3  # Number of conditions (1 is control, others are cond-N-1)\n",
    "n_proteins = 500  # Number of proteins in the dataset\n",
    "n_replicates = 10  # Number of replicates per condition\n",
    "n_peptides = (5, 50)  # (min, max) for peptides per protein\n",
    "condition_shifts = [0, 1, 2]  # Shifts for the conditions\n",
    "nPro_to_perturb = 250  # Number of proteins to perturb\n",
    "perturb_conds = ['cond2']  # Conditions to perturb\n",
    "perturb_overlap = False  # Allow overlap between perturbed peptides\n",
    "pertMag_range = (.5, 1.5)  # Range of values to perturb the peptides with (uniform)\n",
    "\n",
    "# Generate the paths for it.\n",
    "output_path, figure_path = setup_simulation_paths( simID )\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"{'Simulation ID:':<18} {simID}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"• Simulation Data:\")\n",
    "print(f\"    - Generates a synthetic proteomics dataset with {n_proteins} proteins.\")\n",
    "print(f\"    - Each protein has {n_peptides[0]}–{n_peptides[1]} peptides, across {n_condition} conditions.\")\n",
    "print(f\"    - The first condition is the control; the rest are experimental.\")\n",
    "print(\"• Simulation Goal:\")\n",
    "print(\"    - Compare the effects of perturbations on the data, both in complete and imputed forms.\")\n",
    "print(\"• Parameters:\")\n",
    "print(f\"    - RNG seed: {seed}\")\n",
    "print(f\"    - {n_condition} conditions (control + {n_condition-1} treatments), log2 shifts: {condition_shifts}\")\n",
    "print(f\"    - {n_proteins} proteins × {n_replicates} replicates, {n_peptides[0]}–{n_peptides[1]} peptides/protein\")\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins (overlap={perturb_overlap})\")\n",
    "print(f\"    - Perturbation in conditions: {perturb_conds}, magnitude range: {pertMag_range}\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 1: Generate Protein Mean Values (with outliers)\")\n",
    "print(f\"    - Using seed: {seed}\")\n",
    "mean_values = sims.normal_distribution_with_outliers(\n",
    "    mu=20,\n",
    "    sd=2,\n",
    "    size=n_proteins,\n",
    "    is_log2=False,\n",
    "    outlier_fraction=0.10,\n",
    "    outlier_sd_multiplier=1.0,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Generated {len(mean_values)} protein mean values (log2 scale)\")\n",
    "print(f\"    - Stats: mean={np.mean(mean_values):.2f}, std={np.std(mean_values):.2f}, min={np.min(mean_values):.2f}, max={np.max(mean_values):.2f}\")\n",
    "print(f\"    - Outliers: fraction=10.0%, sd-multiplier=1.0\")\n",
    "mean_values = 2 ** mean_values\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 2: Generate Protein Coefficient of Variation (CV) Values\")\n",
    "cv_values = sims.lognormal_distribution(\n",
    "    mu=10,\n",
    "    med=8,\n",
    "    size=n_proteins,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Log-normal distribution: mean=10, median=8\")\n",
    "print(f\"    - Generated {len(cv_values)} CV values\")\n",
    "print(f\"    - Stats: mean={np.mean(cv_values):.2f}, std={np.std(cv_values):.2f}, min={np.min(cv_values):.2f}, max={np.max(cv_values):.2f}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 3: Generate Replicates for Control (Biological Reference)\")\n",
    "control_data = sims.generate_replicates(\n",
    "    mean_values,\n",
    "    cv_values,\n",
    "    meanScale='raw',\n",
    "    cvType='percent',\n",
    "    nReps=n_replicates,\n",
    "    randomizeCV=True,\n",
    "    as_dataframe=True,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Generated {control_data.shape[1]} control replicates for {control_data.shape[0]} proteins\")\n",
    "print(f\"    - This subset will serve as the control for all treatments.\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 4: Generate Number of Peptides per Protein\")\n",
    "pepN_cnts = sims.generate_peptide_counts(\n",
    "    n_proteins=n_proteins,\n",
    "    min_peptides=n_peptides[0],\n",
    "    max_peptides=n_peptides[1],\n",
    "    alpha=0.5,\n",
    "    beta=3,\n",
    ")\n",
    "print(f\"    - Beta-binomial: min={n_peptides[0]}, max={n_peptides[1]}, alpha=0.5, beta=3\")\n",
    "print(f\"    - Generated {len(pepN_cnts)} peptide counts\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 5: Generate Peptide-Level Data from Protein-Level Data\")\n",
    "pep_data = sims.generate_peptide_level(\n",
    "    control_data,\n",
    "    pepN_cnts,\n",
    "    is_log2=False,\n",
    "    repStd=(0.1, 0.25),\n",
    "    outlier_fraction=0.0001,\n",
    "    outlier_multiplier=0.01,\n",
    "    add_noise=True,\n",
    "    noise_sd=0.10,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Peptide-level data: {pep_data.shape[0]} peptides × {pep_data.shape[1]} samples\")\n",
    "print(f\"    - Noise: sd=0.10, Outliers: fraction=0.0001, multiplier=0.01\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 6: Generate Condition Mappers\")\n",
    "condition_sample_map, condition_shifts = sims.generate_condition_mappers(\n",
    "    n_condition=n_condition-1,\n",
    "    n_replicates=n_replicates,\n",
    "    condition_shifts=condition_shifts[1:],\n",
    "    control_name='control',\n",
    "    condition_suffix='cond',\n",
    ")\n",
    "print(f\"    - Condition sample map keys: {list(condition_sample_map.keys())}\")\n",
    "print(f\"    - Condition shifts: {condition_shifts}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 7: Generate Complete Peptide-Level Data for All Conditions\")\n",
    "generated_data = sims.generate_complete_data(\n",
    "    pep_data,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    shift_scale=0.10,\n",
    "    is_log2=False,\n",
    "    add_noise=False,\n",
    "    noise_sd=0.10,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Complete dataset: {generated_data.shape[0]} peptides × {generated_data.shape[1]} samples\")\n",
    "print(f\"    - Noise: sd=0.10, shift_scale=0.10, no additional noise added\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# generated_data.to_feather(f\"{output_path}1_GeneratedData.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad959b8",
   "metadata": {},
   "source": [
    "### Perturbation Pattern 1: Two Peptides (twoPep)\n",
    "\n",
    "Perturbs exactly **2 peptides** per protein in the same direction. This scenario tests detection of minimal proteoform changes—the smallest signal that might represent a post-translational modification affecting a localized region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f4d75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two Peptides Perturbation Setup\n",
      "\n",
      "==================================================\n",
      "• Step 1: Perturbation Setup\n",
      "    - Perturbing 250/500 proteins with 2 peptides each\n",
      "    - Conditions: ['cond2'], Overlap: False, Magnitude range: (0.5, 1.5)\n",
      "    - Proteins selected for perturbation: ['pro_362' 'pro_74' 'pro_375' 'pro_156' 'pro_105'] ... (total: 250)\n",
      "    - Applying perturbations to selected proteins and peptides...\n",
      "    - Total perturbations applied: 500\n",
      "    - Perturbed data shape: (5583, 30)\n",
      "    - Building test data object with perturbation map...\n",
      "\n",
      "==================================================\n",
      "• Step 2: Imputation Setup\n",
      "    - Simulating missing data (amputation)...\n",
      "    - Introduced missing data with rate=35.0%\n",
      "    - Imputing missing data using downshifted imputation...\n",
      "    - Imputed missing data with downshift=2.0 and lowPct=0.15\n",
      "    - Building final test data object with imputed data...\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Two Peptides Perturbation Setup\")\n",
    "perturb_name = \"twoPep\"  # Perturbation scenario name\n",
    "nPep_to_perturb = 2  # Number of peptides to perturb; if > 1 then it is a fraction\n",
    "perturb_dir_setup = \"same\"  # Direction of perturbation: [random, same]\n",
    "np.random.seed(seed)  # Set the seed for reproducibility\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 1: Perturbation Setup\")\n",
    "simulated_data = generated_data.copy()\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins with {nPep_to_perturb} peptides each\")\n",
    "print(f\"    - Conditions: {perturb_conds}, Overlap: {perturb_overlap}, Magnitude range: {pertMag_range}\")\n",
    "\n",
    "unique_proteins = simulated_data.reset_index()[\"Protein\"].unique()\n",
    "proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "print(f\"    - Proteins selected for perturbation: {proteins_to_perturb[:5]} ... (total: {len(proteins_to_perturb)})\")\n",
    "\n",
    "\n",
    "# Subset the data for perturbation\n",
    "tmp = np.log2(simulated_data).copy()\n",
    "perturb_data = tmp.loc[proteins_to_perturb]\n",
    "unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "\n",
    "perturb_values = sims.generate_perturb_values(\n",
    "    nPro_to_perturb=nPro_to_perturb,\n",
    "    nCond=nPep_to_perturb,\n",
    "    pertMag_range=pertMag_range,\n",
    "    direction=\"same\",\n",
    ")\n",
    "\n",
    "# Find the condition for each protein\n",
    "perturb_conditions = np.random.choice(perturb_conds, nPro_to_perturb)\n",
    "\n",
    "# Go through the proteins and perturb single peptide in each\n",
    "dictCnt = 0\n",
    "perturbation_map = {}\n",
    "print(\"    - Applying perturbations to selected proteins and peptides...\")\n",
    "for i, protein in enumerate(proteins_to_perturb):\n",
    "    # Get the current protein data\n",
    "    cur_data = perturb_data.loc[protein]\n",
    "    # Get the perturbation value\n",
    "    perturb_value = perturb_values[i]\n",
    "    # Select n number of non-consecutive peptides to perturb\n",
    "    pep_pos = np.random.choice(cur_data.index, nPep_to_perturb, replace=False)\n",
    "    cond = perturb_conditions[i]\n",
    "    # Get the perturbation condition\n",
    "    perturb_samples = condition_sample_map[cond]\n",
    "    for j in range(nPep_to_perturb):\n",
    "        # Get the peptides to perturb for the current condition\n",
    "        perturb_peptide = pep_pos[j]\n",
    "        # Get the perturbation peptide intensity\n",
    "        perturb_intensity = cur_data.loc[perturb_peptide, perturb_samples]\n",
    "        # Update the perturbation peptide intensity\n",
    "        perturb_intensity += perturb_value[j]\n",
    "        perturb_data.loc[(protein, perturb_peptide), perturb_samples] = perturb_intensity\n",
    "        perturbation_map[dictCnt] = {\n",
    "            \"Protein\": protein,\n",
    "            \"Peptide\": perturb_peptide,\n",
    "            \"pertCondition\": cond,\n",
    "            \"pertShift\": perturb_value[j],\n",
    "        }\n",
    "        dictCnt += 1\n",
    "\n",
    "print(f\"    - Total perturbations applied: {dictCnt}\")\n",
    "\n",
    "perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "perturbed_data = (np.power(2, perturbed_data))\n",
    "\n",
    "print(f\"    - Perturbed data shape: {perturbed_data.shape}\")\n",
    "\n",
    "# --- Build Test Data Object ---\n",
    "print(\"    - Building test data object with perturbation map...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=perturbed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=None,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_complete_InputData.feather\")\n",
    "complete_data = test_data.copy()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 2: Imputation Setup\")\n",
    "\n",
    "# --- Simulate Missing Data (Amputation) ---\n",
    "print(\"    - Simulating missing data (amputation)...\")\n",
    "missing_data = sims.amputation(\n",
    "    data=perturbed_data,\n",
    "    unique_proteins=unique_proteins,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    n_amputate_1=100,\n",
    "    n_amputate_2=100,\n",
    "    n_amputate_3=100,\n",
    "    missing_rate=0.35,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Introduced missing data with rate=35.0%\")\n",
    "\n",
    "# --- Impute Missing Data ---\n",
    "print(\"    - Imputing missing data using downshifted imputation...\")\n",
    "imputed_data = sims.downshifted_imputation(\n",
    "    data=missing_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    is_log2=False,\n",
    "    shiftMag=2,\n",
    "    lowPct=0.15,\n",
    "    minValue=8,\n",
    "    impute_all=False,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Imputed missing data with downshift=2.0 and lowPct=0.15\")\n",
    "\n",
    "# --- Build Final Test Data Object ---\n",
    "print(\"    - Building final test data object with imputed data...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=imputed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=missing_data,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_imputed_InputData.feather\")\n",
    "imputed_data = test_data.copy()\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1a2b8",
   "metadata": {},
   "source": [
    "### Perturbation Pattern 2: Half Peptides (halfPep)\n",
    "\n",
    "Perturbs **50%** of peptides per protein. This simulates a scenario where half the protein is affected—potentially representing domain-specific changes or partial degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e15a6124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Half of the Peptides (50%) Perturbation Setup\n",
      "\n",
      "==================================================\n",
      "• Step 1: Perturbation Setup\n",
      "    - Perturbing 250/500 proteins with 50% peptides each\n",
      "    - Conditions: ['cond2'], Overlap: False, Magnitude range: (0.5, 1.5)\n",
      "    - Proteins selected for perturbation: ['pro_362' 'pro_74' 'pro_375' 'pro_156' 'pro_105'] ... (total: 250)\n",
      "    - Applying perturbations to selected proteins and peptides...\n",
      "    - Total perturbations applied: 1343\n",
      "    - Perturbed data shape: (5583, 30)\n",
      "    - Building test data object with perturbation map...\n",
      "\n",
      "==================================================\n",
      "• Step 2: Imputation Setup\n",
      "    - Simulating missing data (amputation)...\n",
      "    - Introduced missing data with rate=35.0%\n",
      "    - Imputing missing data using downshifted imputation...\n",
      "    - Imputed missing data with downshift=2.0 and lowPct=0.15\n",
      "    - Building final test data object with imputed data...\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Half of the Peptides (50%) Perturbation Setup\")\n",
    "perturb_name = \"halfPep\"  # Perturbation scenario name\n",
    "nPep_to_perturb = 0.50  # Number of peptides to perturb; if > 1 then it is a fraction\n",
    "perturb_dir_setup = \"same\"  # Direction of perturbation: [random, same]\n",
    "np.random.seed(seed)  # Set the seed for reproducibility\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 1: Perturbation Setup\")\n",
    "simulated_data = generated_data.copy()\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins with {nPep_to_perturb*100:.0f}% peptides each\")\n",
    "print(f\"    - Conditions: {perturb_conds}, Overlap: {perturb_overlap}, Magnitude range: {pertMag_range}\")\n",
    "unique_proteins = simulated_data.reset_index()[\"Protein\"].unique()\n",
    "proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "print(f\"    - Proteins selected for perturbation: {proteins_to_perturb[:5]} ... (total: {len(proteins_to_perturb)})\")\n",
    "\n",
    "# Subset the data for perturbation\n",
    "tmp = np.log2(simulated_data).copy()\n",
    "perturb_data = tmp.loc[proteins_to_perturb]\n",
    "unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "\n",
    "# Go through the proteins and perturb single peptide in each\n",
    "dictCnt = 0\n",
    "perturbation_map = {}\n",
    "print(\"    - Applying perturbations to selected proteins and peptides...\")\n",
    "for i, protein in enumerate(proteins_to_perturb):\n",
    "    cur_data = perturb_data.loc[protein]\n",
    "    n = int( np.floor(nPep_to_perturb * len(cur_data) ))\n",
    "    if n < 2: n = 2\n",
    "    # print(f\"Protein: {protein} - Peptides: {n}, Total Peptides: {len(cur_data)}\")\n",
    "    pepNums = np.random.choice(cur_data.index, n, replace=False)\n",
    "    # Identify the conditions to perturb\n",
    "    conds = np.random.choice(perturb_conds, len(pepNums), replace=True)\n",
    "    # Identify the magnitude of perturbation\n",
    "    pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], len(pepNums))\n",
    "    #\n",
    "    if perturb_dir_setup == \"random\":\n",
    "        pertDir = np.random.choice([-1, 1], len(pepNums), replace=True)\n",
    "    elif perturb_dir_setup == \"same\":\n",
    "        # Pick random direction\n",
    "        pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "        pertDir = np.repeat(pertDir, len(pepNums))\n",
    "    \n",
    "    for j in range(len(pepNums)):\n",
    "        perturb_samples = condition_sample_map[conds[j]]\n",
    "        # Get the peptides to perturb for the current condition\n",
    "        perturb_peptide = pepNums[j]\n",
    "        # Get the perturbation peptide intensity\n",
    "        perturb_intensity = cur_data.loc[perturb_peptide, perturb_samples]\n",
    "        # Update the perturbation peptide intensity\n",
    "        perturb_intensity += pertMag[j] * pertDir[j]\n",
    "        perturb_data.loc[(protein, perturb_peptide), perturb_samples] = perturb_intensity\n",
    "        perturbation_map[dictCnt] = {\n",
    "            \"Protein\": protein,\n",
    "            \"Peptide\": perturb_peptide,\n",
    "            \"pertCondition\": conds[j],\n",
    "            \"pertShift\": pertMag[j] * pertDir[j],\n",
    "        }\n",
    "        dictCnt += 1\n",
    "\n",
    "print(f\"    - Total perturbations applied: {dictCnt}\")\n",
    "\n",
    "perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "perturbed_data = (np.power(2, perturbed_data))\n",
    "print(f\"    - Perturbed data shape: {perturbed_data.shape}\")\n",
    "\n",
    "# --- Build Test Data Object ---\n",
    "print(\"    - Building test data object with perturbation map...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=perturbed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=None,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_complete_InputData.feather\")\n",
    "complete_data = test_data.copy()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 2: Imputation Setup\")\n",
    "\n",
    "# --- Simulate Missing Data (Amputation) ---\n",
    "print(\"    - Simulating missing data (amputation)...\")\n",
    "missing_data = sims.amputation(\n",
    "    data=perturbed_data,\n",
    "    unique_proteins=unique_proteins,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    n_amputate_1=100,\n",
    "    n_amputate_2=100,\n",
    "    n_amputate_3=100,\n",
    "    missing_rate=0.35,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Introduced missing data with rate=35.0%\")\n",
    "\n",
    "# --- Impute Missing Data ---\n",
    "print(\"    - Imputing missing data using downshifted imputation...\")\n",
    "imputed_data = sims.downshifted_imputation(\n",
    "    data=missing_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    is_log2=False,\n",
    "    shiftMag=2,\n",
    "    lowPct=0.15,\n",
    "    minValue=8,\n",
    "    impute_all=False,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Imputed missing data with downshift=2.0 and lowPct=0.15\")\n",
    "\n",
    "# --- Build Final Test Data Object ---\n",
    "print(\"    - Building final test data object with imputed data...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=imputed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=missing_data,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_imputed_InputData.feather\")\n",
    "imputed_data = test_data.copy()\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758c976",
   "metadata": {},
   "source": [
    "### Perturbation Pattern 3: Majority Peptides (halfPlusPep)\n",
    "\n",
    "Perturbs **70%** of peptides per protein. Tests near-complete protein-level changes where only a minority of peptides remain unaffected—approaching traditional differential expression scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576b74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than Half of the Peptides (70%) Perturbation Setup\n",
      "\n",
      "==================================================\n",
      "• Step 1: Perturbation Setup\n",
      "    - Perturbing 250/500 proteins with 70% peptides each\n",
      "    - Conditions: ['cond2'], Overlap: False, Magnitude range: (0.5, 1.5)\n",
      "    - Proteins selected for perturbation: ['pro_362' 'pro_74' 'pro_375' 'pro_156' 'pro_105'] ... (total: 250)\n",
      "    - Applying perturbations to selected proteins and peptides...\n",
      "    - Total perturbations applied: 2104\n",
      "    - Perturbed data shape: (5583, 30)\n",
      "    - Building test data object with perturbation map...\n",
      "\n",
      "==================================================\n",
      "• Step 2: Imputation Setup\n",
      "    - Simulating missing data (amputation)...\n",
      "    - Introduced missing data with rate=35.0%\n",
      "    - Imputing missing data using downshifted imputation...\n",
      "    - Imputed missing data with downshift=2.0 and lowPct=0.15\n",
      "    - Building final test data object with imputed data...\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"More than Half of the Peptides (70%) Perturbation Setup\")\n",
    "perturb_name = \"halfPlusPep\"  # Perturbation scenario name\n",
    "nPep_to_perturb = 0.70  # Number of peptides to perturb; if > 1 then it is a fraction\n",
    "perturb_dir_setup = \"same\"  # Direction of perturbation: [random, same]\n",
    "np.random.seed(seed)  # Set the seed for reproducibility\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 1: Perturbation Setup\")\n",
    "simulated_data = generated_data.copy()\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins with {nPep_to_perturb*100:.0f}% peptides each\")\n",
    "print(f\"    - Conditions: {perturb_conds}, Overlap: {perturb_overlap}, Magnitude range: {pertMag_range}\")\n",
    "unique_proteins = simulated_data.reset_index()[\"Protein\"].unique()\n",
    "proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "print(f\"    - Proteins selected for perturbation: {proteins_to_perturb[:5]} ... (total: {len(proteins_to_perturb)})\")   \n",
    "\n",
    "# Subset the data for perturbation\n",
    "tmp = np.log2(simulated_data).copy()\n",
    "perturb_data = tmp.loc[proteins_to_perturb]\n",
    "unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "\n",
    "# Go through the proteins and perturb single peptide in each\n",
    "dictCnt = 0\n",
    "perturbation_map = {}\n",
    "print(\"    - Applying perturbations to selected proteins and peptides...\")\n",
    "for i, protein in enumerate(proteins_to_perturb):\n",
    "    cur_data = perturb_data.loc[protein]\n",
    "    n = int( np.ceil(nPep_to_perturb * len(cur_data) ))\n",
    "    if n < 2: n = 2\n",
    "    # print(f\"Protein: {protein} - Peptides: {n}, Total Peptides: {len(cur_data)}\")\n",
    "    pepNums = np.random.choice(cur_data.index, n, replace=False)\n",
    "    # Identify the conditions to perturb\n",
    "    conds = np.random.choice(perturb_conds, len(pepNums), replace=True)\n",
    "    # Identify the magnitude of perturbation\n",
    "    pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], len(pepNums))\n",
    "    #\n",
    "    if perturb_dir_setup == \"random\":\n",
    "        pertDir = np.random.choice([-1, 1], len(pepNums), replace=True)\n",
    "    elif perturb_dir_setup == \"same\":\n",
    "        # Pick random direction\n",
    "        pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "        pertDir = np.repeat(pertDir, len(pepNums))\n",
    "    \n",
    "    for j in range(len(pepNums)):\n",
    "        perturb_samples = condition_sample_map[conds[j]]\n",
    "        # Get the peptides to perturb for the current condition\n",
    "        perturb_peptide = pepNums[j]\n",
    "        # Get the perturbation peptide intensity\n",
    "        perturb_intensity = cur_data.loc[perturb_peptide, perturb_samples]\n",
    "        # Update the perturbation peptide intensity\n",
    "        perturb_intensity += pertMag[j] * pertDir[j]\n",
    "        perturb_data.loc[(protein, perturb_peptide), perturb_samples] = perturb_intensity\n",
    "        perturbation_map[dictCnt] = {\n",
    "            \"Protein\": protein,\n",
    "            \"Peptide\": perturb_peptide,\n",
    "            \"pertCondition\": conds[j],\n",
    "            \"pertShift\": pertMag[j] * pertDir[j],\n",
    "        }\n",
    "        dictCnt += 1\n",
    "\n",
    "print(f\"    - Total perturbations applied: {dictCnt}\")\n",
    "\n",
    "# --- Combine Perturbed and Unchanged Data ---\n",
    "perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "perturbed_data = (np.power(2, perturbed_data))\n",
    "print(f\"    - Perturbed data shape: {perturbed_data.shape}\")\n",
    "\n",
    "# --- Build Test Data Object ---\n",
    "print(\"    - Building test data object with perturbation map...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=perturbed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=None,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_complete_InputData.feather\")\n",
    "complete_data = test_data.copy()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 2: Imputation Setup\")\n",
    "\n",
    "# --- Simulate Missing Data (Amputation) ---\n",
    "print(\"    - Simulating missing data (amputation)...\")\n",
    "missing_data = sims.amputation(\n",
    "    data=perturbed_data,\n",
    "    unique_proteins=unique_proteins,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    n_amputate_1=100,\n",
    "    n_amputate_2=100,\n",
    "    n_amputate_3=100,\n",
    "    missing_rate=0.35,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Introduced missing data with rate=35.0%\")\n",
    "\n",
    "# --- Impute Missing Data ---\n",
    "print(\"    - Imputing missing data using downshifted imputation...\")\n",
    "imputed_data = sims.downshifted_imputation(\n",
    "    data=missing_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    is_log2=False,\n",
    "    shiftMag=2,\n",
    "    lowPct=0.15,\n",
    "    minValue=8,\n",
    "    impute_all=False,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Imputed missing data with downshift=2.0 and lowPct=0.15\")\n",
    "\n",
    "# --- Build Final Test Data Object ---\n",
    "print(\"    - Building final test data object with imputed data...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=imputed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=missing_data,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_imputed_InputData.feather\")\n",
    "imputed_data = test_data.copy()\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b840bb2",
   "metadata": {},
   "source": [
    "### Perturbation Pattern 4: Random Peptides (randomPep)\n",
    "\n",
    "Perturbs a **random 10–50%** of peptides per protein (minimum 2). This is the most realistic scenario, simulating the variable nature of biological perturbations where the extent of change varies across proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12fa67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Number of Peptides (2 to 50%) Perturbation Setup\n",
      "\n",
      "==================================================\n",
      "• Step 1: Perturbation Setup\n",
      "    - Perturbing 250/500 proteins with -1 peptides each\n",
      "    - Conditions: ['cond2'], Overlap: False, Magnitude range: (0.5, 1.5)\n",
      "    - Proteins selected for perturbation: ['pro_362' 'pro_74' 'pro_375' 'pro_156' 'pro_105'] ... (total: 250)\n",
      "    - Applying perturbations to selected proteins and peptides...\n",
      "    - Total perturbations applied: 835\n",
      "    - Perturbed data shape: (5583, 30)\n",
      "    - Building test data object with perturbation map...\n",
      "\n",
      "==================================================\n",
      "• Step 2: Imputation Setup\n",
      "    - Simulating missing data (amputation)...\n",
      "    - Introduced missing data with rate=35.0%\n",
      "    - Imputing missing data using downshifted imputation...\n",
      "    - Imputed missing data with downshift=2.5 and lowPct=0.10\n",
      "    - Building final test data object with imputed data...\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Number of Peptides (2 to 50%) Perturbation Setup\")\n",
    "perturb_name = \"randomPep\"  # Perturbation scenario name\n",
    "nPep_to_perturb = -1  # Number of peptides to perturb; if > 1 then it is a fraction\n",
    "perturb_dir_setup = \"same\"  # Direction of perturbation: [random, same]\n",
    "np.random.seed(seed)  # Set the seed for reproducibility\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 1: Perturbation Setup\")\n",
    "simulated_data = generated_data.copy()\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins with {nPep_to_perturb} peptides each\")\n",
    "print(f\"    - Conditions: {perturb_conds}, Overlap: {perturb_overlap}, Magnitude range: {pertMag_range}\")\n",
    "\n",
    "# Get the unique proteins\n",
    "unique_proteins = simulated_data.reset_index()[\"Protein\"].unique()\n",
    "# Select random proteins to perturb\n",
    "proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "print(f\"    - Proteins selected for perturbation: {proteins_to_perturb[:5]} ... (total: {len(proteins_to_perturb)})\")\n",
    "# Pick a fraction between 0.1 and 0.5 of the peptides to perturb\n",
    "if nPep_to_perturb == -1:\n",
    "    nPep_array = np.random.uniform(0.1, 0.5, len(unique_proteins))\n",
    "elif nPep_to_perturb < 1 and nPep_to_perturb > 0:\n",
    "    nPep_array = np.repeat(nPep_to_perturb, len(unique_proteins))\n",
    "elif nPep_to_perturb >= 1:\n",
    "    nPep_array = np.repeat(nPep_to_perturb, len(unique_proteins))\n",
    "\n",
    "# --- Subset Data for Perturbation ---\n",
    "tmp = np.log2(simulated_data).copy()\n",
    "perturb_data = tmp.loc[proteins_to_perturb]\n",
    "unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "\n",
    "# --- Apply Perturbations to Selected Proteins and Peptides ---\n",
    "dictCnt = 0\n",
    "perturbation_map = {}\n",
    "print(\"    - Applying perturbations to selected proteins and peptides...\")\n",
    "for i, protein in enumerate(proteins_to_perturb):\n",
    "    cur_data = perturb_data.loc[protein]\n",
    "    if nPep_to_perturb < 1:\n",
    "        n = int(nPep_array[i] * len(cur_data))\n",
    "        # Ensure minimum of 1 peptide is perturbed\n",
    "        if n < 2: n = 2\n",
    "    elif nPep_to_perturb >= 1:\n",
    "        n = int(nPep_to_perturb)\n",
    "    # print(f\"Protein: {protein} - Peptides: {n}, Total Peptides: {len(cur_data)}\")\n",
    "    pepNums = np.random.choice(cur_data.index, n, replace=False)\n",
    "    # Identify the conditions to perturb\n",
    "    conds = np.random.choice(perturb_conds, len(pepNums), replace=True)\n",
    "    # Identify the magnitude of perturbation\n",
    "    pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], len(pepNums))\n",
    "    #\n",
    "    if perturb_dir_setup == \"random\":\n",
    "        pertDir = np.random.choice([-1, 1], len(pepNums), replace=True)\n",
    "    elif perturb_dir_setup == \"same\":\n",
    "        # Pick random direction\n",
    "        pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "        pertDir = np.repeat(pertDir, len(pepNums))\n",
    "    \n",
    "    for j in range(len(pepNums)):\n",
    "        perturb_samples = condition_sample_map[conds[j]]\n",
    "        # Get the peptides to perturb for the current condition\n",
    "        perturb_peptide = pepNums[j]\n",
    "        # Get the perturbation peptide intensity\n",
    "        perturb_intensity = cur_data.loc[perturb_peptide, perturb_samples]\n",
    "        # Update the perturbation peptide intensity\n",
    "        perturb_intensity += pertMag[j] * pertDir[j]\n",
    "        perturb_data.loc[(protein, perturb_peptide), perturb_samples] = perturb_intensity\n",
    "        perturbation_map[dictCnt] = {\n",
    "            \"Protein\": protein,\n",
    "            \"Peptide\": perturb_peptide,\n",
    "            \"pertCondition\": conds[j],\n",
    "            \"pertShift\": pertMag[j] * pertDir[j],\n",
    "        }\n",
    "        dictCnt += 1\n",
    "print(f\"    - Total perturbations applied: {dictCnt}\")\n",
    "\n",
    "perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "perturbed_data = (np.power(2, perturbed_data))\n",
    "print(f\"    - Perturbed data shape: {perturbed_data.shape}\")\n",
    "\n",
    "# --- Build Test Data Object ---\n",
    "print(\"    - Building test data object with perturbation map...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=perturbed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=None,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_complete_InputData.feather\")\n",
    "complete_data = test_data.copy()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"• Step 2: Imputation Setup\")\n",
    "\n",
    "# --- Simulate Missing Data (Amputation) ---\n",
    "print(\"    - Simulating missing data (amputation)...\")\n",
    "missing_data = sims.amputation(\n",
    "    data=perturbed_data,\n",
    "    unique_proteins=unique_proteins,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    n_amputate_1=100,\n",
    "    n_amputate_2=100,\n",
    "    n_amputate_3=100,\n",
    "    missing_rate=0.35,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Introduced missing data with rate=35.0%\")\n",
    "\n",
    "# --- Impute Missing Data ---\n",
    "print(\"    - Imputing missing data using downshifted imputation...\")\n",
    "imputed_data = sims.downshifted_imputation(\n",
    "    data=missing_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    is_log2=False,\n",
    "    shiftMag = 2,\n",
    "    lowPct = 0.15,\n",
    "    minValue = 8,\n",
    "    impute_all=False,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Imputed missing data with downshift=2.5 and lowPct=0.10\")\n",
    "\n",
    "# --- Build Final Test Data Object ---\n",
    "print(\"    - Building final test data object with imputed data...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=imputed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=missing_data,\n",
    ")\n",
    "test_data.to_feather(f\"{output_path}2_{perturb_name}_imputed_InputData.feather\")\n",
    "imputed_data = test_data.copy()\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9b08b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "• Completed generation of 8 versions for simulation: Sim1\n",
      "    - Elapsed time: 00h:00m:09s\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nVersions = 4 * 2  # 4 perturbation types, each with complete and imputed data\n",
    "elapsed = utils.prettyTimer(utils.getTime() - stTime)\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(f\"• Completed generation of {nVersions} versions for simulation: {simID}\")\n",
    "print(f\"    - Elapsed time: {elapsed}\")\n",
    "print(f\"{'-'*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f616ed8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simulation 2: Missingness Level Impact\n",
    "\n",
    "**Objective:** Quantify how increasing proportions of missing data affect detection performance after imputation.\n",
    "\n",
    "**Experimental Design:**\n",
    "- **Base dataset**: Same structure as Sim1 (500 proteins, 3 conditions, 10 replicates)\n",
    "- **Perturbation**: Random 10–50% pattern (same as randomPep from Sim1)\n",
    "- **Missingness levels**: Factorial design with 5 × 5 = 25 combinations\n",
    "  - Protein-level: 0%, 20%, 40%, 60%, 80% of proteins have missing values\n",
    "  - Peptide-level: 0%, 20%, 40%, 60%, 80% of peptides within affected proteins are missing\n",
    "- **Imputation**: Downshifted imputation applied uniformly\n",
    "\n",
    "**Key Question:** At what missingness threshold does performance critically degrade?\n",
    "\n",
    "**Output Files:** `./data/Sim2/2_Pro{rate}_Pep{rate}_imputed_InputData.feather`\n",
    "\n",
    "### Base Dataset and Perturbation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4b3972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Simulation ID:     Sim2\n",
      "==================================================\n",
      "• Simulation Data:\n",
      "    - Generates a synthetic proteomics dataset with 500 proteins.\n",
      "    - Each protein has 5–50 peptides, across 3 conditions.\n",
      "    - The first condition is the control; the rest are experimental.\n",
      "    - Uses the random (2 to 50%) peptide perturbation strategy as the base and adds different levels of missingness.\n",
      "• Simulation Goal:\n",
      "    - Compare the effects of of missingness rates in protein and peptide levels with imputation.\n",
      "• Parameters:\n",
      "    - RNG seed: 42\n",
      "    - 3 conditions (control + 2 treatments), log2 shifts: [0, 1, 2]\n",
      "    - 500 proteins × 10 replicates, 5–50 peptides/protein\n",
      "    - Perturbing 250/500 proteins (overlap=False)\n",
      "    - Perturbation in conditions: ['cond2'], magnitude range: (0.5, 1.5)\n",
      "==================================================\n",
      "\n",
      "• Step 1: Generate Protein Mean Values (with outliers)\n",
      "    - Using seed: 42\n",
      "    - Generated 500 protein mean values (log2 scale)\n",
      "    - Stats: mean=20.01, std=1.96, min=13.52, max=27.71\n",
      "    - Outliers: fraction=10.0%, sd-multiplier=1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 2: Generate Protein Coefficient of Variation (CV) Values\n",
      "    - Log-normal distribution: mean=10, median=8\n",
      "    - Generated 500 CV values\n",
      "    - Stats: mean=10.07, std=8.36, min=0.92, max=104.93\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 3: Generate Replicates for Control (Biological Reference)\n",
      "    - Generated 10 control replicates for 500 proteins\n",
      "    - This subset will serve as the control for all treatments.\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 4: Generate Number of Peptides per Protein\n",
      "    - Beta-binomial: min=5, max=50, alpha=0.5, beta=3\n",
      "    - Generated 500 peptide counts\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 5: Generate Peptide-Level Data from Protein-Level Data\n",
      "    - Peptide-level data: 5583 peptides × 12 samples\n",
      "    - Noise: sd=0.10, Outliers: fraction=0.0001, multiplier=0.01\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 6: Generate Condition Mappers\n",
      "    - Condition sample map keys: ['control', 'cond1', 'cond2']\n",
      "    - Condition shifts: {'control': 0, 'cond1': 1, 'cond2': 2}\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 7: Generate Complete Peptide-Level Data for All Conditions\n",
      "    - Complete dataset: 5583 peptides × 30 samples\n",
      "    - Noise: sd=0.10, shift_scale=0.10, no additional noise added\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 8: Setup Random Number of Peptides to Perturb per Protein\n",
      "    - Perturbing 250/500 proteins with -1 peptides each\n",
      "    - Conditions: ['cond2'], Overlap: False, Magnitude range: (0.5, 1.5)\n",
      "    - Proteins selected for perturbation: ['pro_362' 'pro_74' 'pro_375' 'pro_156' 'pro_105'] ... (total: 250)\n",
      "    - nPep_array example: [0.47337452 0.30041595 0.31575098 0.37358551 0.34634047]... (total: 250)\n",
      "    - Applying perturbations to selected proteins and peptides...\n",
      "    - Total perturbations applied: 835\n",
      "    - Perturbed data shape: (5583, 30)\n",
      "    - Building test data object with perturbation map...\n"
     ]
    }
   ],
   "source": [
    "stTime = utils.getTime()\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "simID = \"Sim2\"\n",
    "seed = 42  # Seed for reproducibility\n",
    "n_condition = 3  # Number of conditions (1 is control, others are cond-N-1)\n",
    "n_proteins = 500  # Number of proteins in the dataset\n",
    "n_replicates = 10  # Number of replicates per condition\n",
    "n_peptides = (5, 50)  # (min, max) for peptides per protein\n",
    "condition_shifts = [0, 1, 2]  # Shifts for the conditions\n",
    "nPro_to_perturb = 250  # Number of proteins to perturb\n",
    "perturb_conds = ['cond2']  # Conditions to perturb\n",
    "perturb_overlap = False  # Allow overlap between perturbed peptides\n",
    "pertMag_range = (.5, 1.5)  # Range of values to perturb the peptides with (uniform)\n",
    "\n",
    "# Generate the paths for it.\n",
    "output_path, figure_path = setup_simulation_paths( simID )\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"{'Simulation ID:':<18} {simID}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"• Simulation Data:\")\n",
    "print(f\"    - Generates a synthetic proteomics dataset with {n_proteins} proteins.\")\n",
    "print(f\"    - Each protein has {n_peptides[0]}–{n_peptides[1]} peptides, across {n_condition} conditions.\")\n",
    "print(f\"    - The first condition is the control; the rest are experimental.\")\n",
    "print(f\"    - Uses the random (2 to 50%) peptide perturbation strategy as the base and adds different levels of missingness.\")\n",
    "print(\"• Simulation Goal:\")\n",
    "print(\"    - Compare the effects of of missingness rates in protein and peptide levels with imputation.\")\n",
    "print(\"• Parameters:\")\n",
    "print(f\"    - RNG seed: {seed}\")\n",
    "print(f\"    - {n_condition} conditions (control + {n_condition-1} treatments), log2 shifts: {condition_shifts}\")\n",
    "print(f\"    - {n_proteins} proteins × {n_replicates} replicates, {n_peptides[0]}–{n_peptides[1]} peptides/protein\")\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins (overlap={perturb_overlap})\")\n",
    "print(f\"    - Perturbation in conditions: {perturb_conds}, magnitude range: {pertMag_range}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "print(\"• Step 1: Generate Protein Mean Values (with outliers)\")\n",
    "print(f\"    - Using seed: {seed}\")\n",
    "mean_values = sims.normal_distribution_with_outliers(\n",
    "    mu=20,\n",
    "    sd=2,\n",
    "    size=n_proteins,\n",
    "    is_log2=False,\n",
    "    outlier_fraction=0.10,\n",
    "    outlier_sd_multiplier=1.0,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Generated {len(mean_values)} protein mean values (log2 scale)\")\n",
    "print(f\"    - Stats: mean={np.mean(mean_values):.2f}, std={np.std(mean_values):.2f}, min={np.min(mean_values):.2f}, max={np.max(mean_values):.2f}\")\n",
    "print(f\"    - Outliers: fraction=10.0%, sd-multiplier=1.0\")\n",
    "mean_values = 2 ** mean_values\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 2: Generate Protein Coefficient of Variation (CV) Values\")\n",
    "cv_values = sims.lognormal_distribution(\n",
    "    mu=10,\n",
    "    med=8,\n",
    "    size=n_proteins,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Log-normal distribution: mean=10, median=8\")\n",
    "print(f\"    - Generated {len(cv_values)} CV values\")\n",
    "print(f\"    - Stats: mean={np.mean(cv_values):.2f}, std={np.std(cv_values):.2f}, min={np.min(cv_values):.2f}, max={np.max(cv_values):.2f}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 3: Generate Replicates for Control (Biological Reference)\")\n",
    "control_data = sims.generate_replicates(\n",
    "    mean_values,\n",
    "    cv_values,\n",
    "    meanScale='raw',\n",
    "    cvType='percent',\n",
    "    nReps=n_replicates,\n",
    "    randomizeCV=True,\n",
    "    as_dataframe=True,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Generated {control_data.shape[1]} control replicates for {control_data.shape[0]} proteins\")\n",
    "print(f\"    - This subset will serve as the control for all treatments.\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 4: Generate Number of Peptides per Protein\")\n",
    "pepN_cnts = sims.generate_peptide_counts(\n",
    "    n_proteins=n_proteins,\n",
    "    min_peptides=n_peptides[0],\n",
    "    max_peptides=n_peptides[1],\n",
    "    alpha=0.5,\n",
    "    beta=3,\n",
    ")\n",
    "print(f\"    - Beta-binomial: min={n_peptides[0]}, max={n_peptides[1]}, alpha=0.5, beta=3\")\n",
    "print(f\"    - Generated {len(pepN_cnts)} peptide counts\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 5: Generate Peptide-Level Data from Protein-Level Data\")\n",
    "pep_data = sims.generate_peptide_level(\n",
    "    control_data,\n",
    "    pepN_cnts,\n",
    "    is_log2=False,\n",
    "    repStd=(0.1, 0.25),\n",
    "    outlier_fraction=0.0001,\n",
    "    outlier_multiplier=0.01,\n",
    "    add_noise=True,\n",
    "    noise_sd=0.10,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Peptide-level data: {pep_data.shape[0]} peptides × {pep_data.shape[1]} samples\")\n",
    "print(f\"    - Noise: sd=0.10, Outliers: fraction=0.0001, multiplier=0.01\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 6: Generate Condition Mappers\")\n",
    "condition_sample_map, condition_shifts = sims.generate_condition_mappers(\n",
    "    n_condition=n_condition-1,\n",
    "    n_replicates=n_replicates,\n",
    "    condition_shifts=condition_shifts[1:],\n",
    "    control_name='control',\n",
    "    condition_suffix='cond',\n",
    ")\n",
    "print(f\"    - Condition sample map keys: {list(condition_sample_map.keys())}\")\n",
    "print(f\"    - Condition shifts: {condition_shifts}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 7: Generate Complete Peptide-Level Data for All Conditions\")\n",
    "generated_data = sims.generate_complete_data(\n",
    "    pep_data,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    shift_scale=0.10,\n",
    "    is_log2=False,\n",
    "    add_noise=False,\n",
    "    noise_sd=0.10,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Complete dataset: {generated_data.shape[0]} peptides × {generated_data.shape[1]} samples\")\n",
    "print(f\"    - Noise: sd=0.10, shift_scale=0.10, no additional noise added\")\n",
    "\n",
    "perturb_name = \"randomPep\"  # Perturbation scenario name\n",
    "nPep_to_perturb = -1  # Number of peptides to perturb; if > 1 then it is a fraction\n",
    "perturb_dir_setup = \"same\"  # Direction of perturbation: [random, same]\n",
    "np.random.seed(seed)  # Set the seed for reproducibility\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 8: Setup Random Number of Peptides to Perturb per Protein\")\n",
    "simulated_data = generated_data.copy()\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins with {nPep_to_perturb} peptides each\")\n",
    "print(f\"    - Conditions: {perturb_conds}, Overlap: {perturb_overlap}, Magnitude range: {pertMag_range}\")\n",
    "unique_proteins = simulated_data.reset_index()[\"Protein\"].unique()\n",
    "proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "print(f\"    - Proteins selected for perturbation: {proteins_to_perturb[:5]} ... (total: {len(proteins_to_perturb)})\")\n",
    "\n",
    "# --- Determine Number of Peptides to Perturb per Protein ---\n",
    "if nPep_to_perturb == -1:\n",
    "    nPep_array = np.random.uniform(0.1, 0.5, len(proteins_to_perturb))\n",
    "elif 0 < nPep_to_perturb < 1:\n",
    "    nPep_array = np.repeat(nPep_to_perturb, len(proteins_to_perturb))\n",
    "else:\n",
    "    nPep_array = np.repeat(int(nPep_to_perturb), len(proteins_to_perturb))\n",
    "print(f\"    - nPep_array example: {nPep_array[:5]}... (total: {len(nPep_array)})\")\n",
    "\n",
    "# --- Subset Data for Perturbation ---\n",
    "tmp = np.log2(simulated_data).copy()\n",
    "perturb_data = tmp.loc[proteins_to_perturb]\n",
    "unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "# --- Apply Perturbations to Selected Proteins and Peptides ---\n",
    "dictCnt = 0\n",
    "perturbation_map = {}\n",
    "print(\"    - Applying perturbations to selected proteins and peptides...\")\n",
    "for i, protein in enumerate(proteins_to_perturb):   \n",
    "    cur_data = perturb_data.loc[protein]\n",
    "    if nPep_to_perturb < 1:\n",
    "        n = int(nPep_array[i] * len(cur_data))\n",
    "        if n < 2: n = 2  # Ensure minimum of 2 peptides are perturbed\n",
    "    elif nPep_to_perturb >= 1:\n",
    "        n = int(nPep_to_perturb)\n",
    "    pepNums = np.random.choice(cur_data.index, n, replace=False)\n",
    "    conds = np.random.choice(perturb_conds, len(pepNums), replace=True)\n",
    "    pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], len(pepNums))\n",
    "    if perturb_dir_setup == \"random\":\n",
    "        pertDir = np.random.choice([-1, 1], len(pepNums), replace=True)\n",
    "    elif perturb_dir_setup == \"same\":\n",
    "        pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "        pertDir = np.repeat(pertDir, len(pepNums))\n",
    "    for j in range(len(pepNums)):\n",
    "        perturb_samples = condition_sample_map[conds[j]]\n",
    "        perturb_peptide = pepNums[j]\n",
    "        perturb_intensity = cur_data.loc[perturb_peptide, perturb_samples]\n",
    "        perturb_intensity += pertMag[j] * pertDir[j]\n",
    "        perturb_data.loc[(protein, perturb_peptide), perturb_samples] = perturb_intensity\n",
    "        perturbation_map[dictCnt] = {\n",
    "            \"Protein\": protein,\n",
    "            \"Peptide\": perturb_peptide,\n",
    "            \"pertCondition\": conds[j],\n",
    "            \"pertShift\": pertMag[j] * pertDir[j],\n",
    "        }\n",
    "        dictCnt += 1\n",
    "print(f\"    - Total perturbations applied: {dictCnt}\")\n",
    "# --- Combine Perturbed and Unchanged Data ---\n",
    "perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "perturbed_data = (np.power(2, perturbed_data))\n",
    "print(f\"    - Perturbed data shape: {perturbed_data.shape}\")\n",
    "# --- Build Test Data Object ---\n",
    "print(\"    - Building test data object with perturbation map...\")\n",
    "test_data = sims.build_test_data(\n",
    "    data=perturbed_data,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    perturbation_map=perturbation_map,\n",
    "    proteins_to_perturb=proteins_to_perturb,\n",
    "    missing_data=None,\n",
    ")\n",
    "complete_data = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7aa413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "• Step 9: Setup and Run for Different Levels of Missingness\n",
      "    - Running for 25 combinations of protein and peptide missingness:\n",
      "     - Version = Protein Missingness: 0, Peptide Missingness: 0, saving as: 2_Pro0_Pep0_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0, Peptide Missingness: 0.2, saving as: 2_Pro0_Pep0.2_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0, Peptide Missingness: 0.4, saving as: 2_Pro0_Pep0.4_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0, Peptide Missingness: 0.6, saving as: 2_Pro0_Pep0.6_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0, Peptide Missingness: 0.8, saving as: 2_Pro0_Pep0.8_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.2, Peptide Missingness: 0, saving as: 2_Pro0.2_Pep0_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.2, Peptide Missingness: 0.2, saving as: 2_Pro0.2_Pep0.2_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.2, Peptide Missingness: 0.4, saving as: 2_Pro0.2_Pep0.4_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.2, Peptide Missingness: 0.6, saving as: 2_Pro0.2_Pep0.6_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.2, Peptide Missingness: 0.8, saving as: 2_Pro0.2_Pep0.8_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.4, Peptide Missingness: 0, saving as: 2_Pro0.4_Pep0_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.4, Peptide Missingness: 0.2, saving as: 2_Pro0.4_Pep0.2_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.4, Peptide Missingness: 0.4, saving as: 2_Pro0.4_Pep0.4_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.4, Peptide Missingness: 0.6, saving as: 2_Pro0.4_Pep0.6_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.4, Peptide Missingness: 0.8, saving as: 2_Pro0.4_Pep0.8_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.6, Peptide Missingness: 0, saving as: 2_Pro0.6_Pep0_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.6, Peptide Missingness: 0.2, saving as: 2_Pro0.6_Pep0.2_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.6, Peptide Missingness: 0.4, saving as: 2_Pro0.6_Pep0.4_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.6, Peptide Missingness: 0.6, saving as: 2_Pro0.6_Pep0.6_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.6, Peptide Missingness: 0.8, saving as: 2_Pro0.6_Pep0.8_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.8, Peptide Missingness: 0, saving as: 2_Pro0.8_Pep0_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.8, Peptide Missingness: 0.2, saving as: 2_Pro0.8_Pep0.2_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.8, Peptide Missingness: 0.4, saving as: 2_Pro0.8_Pep0.4_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.8, Peptide Missingness: 0.6, saving as: 2_Pro0.8_Pep0.6_imputed_InputData_feather\n",
      "     - Version = Protein Missingness: 0.8, Peptide Missingness: 0.8, saving as: 2_Pro0.8_Pep0.8_imputed_InputData_feather\n",
      "\n",
      "--------------------------------------------------\n",
      "• Completed generation of 25 versions for simulation: Sim2\n",
      "    - Elapsed time: 00h:00m:19s\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 9: Setup and Run for Different Levels of Missingness\")\n",
    "missRatePeps = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "missRatePros = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "nVersions = len(missRatePeps) * len(missRatePros)\n",
    "print(f\"    - Running for {nVersions} combinations of protein and peptide missingness:\")\n",
    "for i in missRatePros:\n",
    "    # Calculate the numbers based on the protein missingness\n",
    "    # n_amputate_1 and n_amputate_2 should add to non-perturbed proteins\n",
    "    n_amputate_2 = int(i * len(proteins_to_perturb))\n",
    "    n_amputate_1 = len(proteins_to_perturb) - n_amputate_2\n",
    "    non_perturbed_proteins = np.setdiff1d(unique_proteins, proteins_to_perturb)\n",
    "    n_amputate_3 = int(i * len(non_perturbed_proteins))\n",
    "    for j in missRatePeps:\n",
    "        print(f\"     - Version = Protein Missingness: {i}, Peptide Missingness: {j}, saving as: 2_Pro{i}_Pep{j}_imputed_InputData_feather\")\n",
    "        # Find out the number of \n",
    "        missing_data = sims.amputation(\n",
    "            data = perturbed_data,\n",
    "            unique_proteins = unique_proteins,\n",
    "            proteins_to_perturb = proteins_to_perturb,\n",
    "            condition_shifts = condition_shifts,\n",
    "            condition_sample_map = condition_sample_map,\n",
    "            n_amputate_1 = n_amputate_1,\n",
    "            n_amputate_2 = n_amputate_2,\n",
    "            n_amputate_3 = n_amputate_3,\n",
    "            missing_rate = j, # Peptide missingness rate\n",
    "            seed = seed\n",
    "        )\n",
    "\n",
    "        imputed_data = sims.downshifted_imputation(\n",
    "            data = missing_data,\n",
    "            condition_sample_map = condition_sample_map,\n",
    "            is_log2 = False,\n",
    "            shiftMag = 2,\n",
    "            lowPct = 0.15,\n",
    "            minValue = 8,\n",
    "            impute_all = False,\n",
    "            seed = seed\n",
    "        )\n",
    "        test_data = sims.build_test_data(\n",
    "            data = imputed_data,\n",
    "            condition_sample_map = condition_sample_map,\n",
    "            perturbation_map = perturbation_map,\n",
    "            proteins_to_perturb = proteins_to_perturb,\n",
    "            missing_data = missing_data,\n",
    "        )\n",
    "\n",
    "        test_data.to_feather(f\"{output_path}2_Pro{i}_Pep{j}_imputed_InputData.feather\")\n",
    "\n",
    "elapsed = utils.prettyTimer(utils.getTime() - stTime)\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(f\"• Completed generation of {nVersions} versions for simulation: {simID}\")\n",
    "print(f\"    - Elapsed time: {elapsed}\")\n",
    "print(f\"{'-'*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba769cbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simulation 3: Perturbation Magnitude Sensitivity\n",
    "\n",
    "**Objective:** Determine the minimum perturbation magnitude required for reliable detection across methods.\n",
    "\n",
    "**Experimental Design:**\n",
    "- **Base dataset**: Same structure as Sim1/Sim2\n",
    "- **Perturbation**: Random 10–50% pattern with **random direction** (up or down)\n",
    "- **Magnitude ranges tested** (log2 fold-change):\n",
    "  | Range | Interpretation |\n",
    "  |-------|----------------|\n",
    "  | 0.10–0.25 | Subtle (e.g., phosphorylation stoichiometry) |\n",
    "  | 0.25–0.50 | Small |\n",
    "  | 0.50–0.75 | Moderate |\n",
    "  | 0.75–1.00 | Medium |\n",
    "  | 1.00–1.25 | Substantial |\n",
    "  | 1.25–1.50 | Large |\n",
    "  | 1.50–1.75 | Strong |\n",
    "  | 1.75–2.00 | Very strong (e.g., isoform switching) |\n",
    "- **Data**: Imputed versions only (25% baseline missingness)\n",
    "\n",
    "**Key Question:** What is the practical detection threshold for each method?\n",
    "\n",
    "**Output Files:** `./data/Sim3/2_{low}_{high}_InputData.feather`\n",
    "\n",
    "### Base Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523c6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Simulation ID:     Sim3\n",
      "==================================================\n",
      "• Simulation Data:\n",
      "    - Generates a synthetic proteomics dataset with 500 proteins.\n",
      "    - Each protein has 5–50 peptides, across 3 conditions.\n",
      "    - The first condition is the control; the rest are experimental.\n",
      "    - Uses the random (2 to 50%) peptide perturbation strategy as the base and adds different levels of missingness.\n",
      "• Simulation Goal:\n",
      "    - To evaluate the effect of different perturbation magnitude ranges on downstream analyses.\n",
      "• Parameters:\n",
      "    - RNG seed: 42\n",
      "    - 3 conditions (control + 2 treatments), log2 shifts: [0, 1, 2]\n",
      "    - 500 proteins × 10 replicates, 5–50 peptides/protein\n",
      "    - Perturbing 250/500 proteins (overlap=False)\n",
      "    - Perturbation in conditions: ['cond2']\n",
      "    - Perturbation magnitude ranges tested: \n",
      "       [(0.1, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1.0), (1.0, 1.25), (1.25, 1.5), (1.5, 1.75), (1.75, 2.0)]\n",
      "==================================================\n",
      "\n",
      "• Step 1: Generate Protein Mean Values (with outliers)\n",
      "    - Using seed: 42\n",
      "==================================================\n",
      "\n",
      "• Step 1: Generate Protein Mean Values (with outliers)\n",
      "    - Using seed: 42\n",
      "    - Generated 500 protein mean values (log2 scale)\n",
      "    - Stats: mean=20.01, std=1.96, min=13.52, max=27.71\n",
      "    - Outliers: fraction=10.0%, sd-multiplier=1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 2: Generate Protein Coefficient of Variation (CV) Values\n",
      "    - Log-normal distribution: mean=10, median=8\n",
      "    - Generated 500 CV values\n",
      "    - Stats: mean=10.07, std=8.36, min=0.92, max=104.93\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 3: Generate Replicates for Control (Biological Reference)\n",
      "    - Generated 10 control replicates for 500 proteins\n",
      "    - This subset will serve as the control for all treatments.\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 4: Generate Number of Peptides per Protein\n",
      "    - Beta-binomial: min=5, max=50, alpha=0.5, beta=3\n",
      "    - Generated 500 peptide counts\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 5: Generate Peptide-Level Data from Protein-Level Data\n",
      "    - Peptide-level data: 5583 peptides × 12 samples\n",
      "    - Noise: sd=0.10, Outliers: fraction=0.0001, multiplier=0.01\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 6: Generate Condition Mappers\n",
      "    - Condition sample map keys: ['control', 'cond1', 'cond2']\n",
      "    - Condition shifts: {'control': 0, 'cond1': 1, 'cond2': 2}\n",
      "\n",
      "--------------------------------------------------\n",
      "• Step 7: Generate Complete Peptide-Level Data for All Conditions\n",
      "    - Complete dataset: 5583 peptides × 30 samples\n",
      "    - Noise: sd=0.10, shift_scale=0.10, no additional noise added\n"
     ]
    }
   ],
   "source": [
    "stTime = utils.getTime()\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "simID = \"Sim3\"\n",
    "seed = 42  # Seed for reproducibility\n",
    "n_condition = 3  # Number of conditions (1 is control, others are cond-N-1)\n",
    "n_proteins = 500  # Number of proteins in the dataset\n",
    "n_replicates = 10  # Number of replicates per condition\n",
    "n_peptides = (5, 50)  # (min, max) for peptides per protein\n",
    "condition_shifts = [0, 1, 2]  # Shifts for the conditions\n",
    "nPro_to_perturb = 250  # Number of proteins to perturb\n",
    "perturb_conds = ['cond2']  # Conditions to perturb\n",
    "perturb_overlap = False  # Allow overlap between perturbed peptides\n",
    "# Magnitude of perturbations to simulate\n",
    "perturbationRanges = [\n",
    "    (0.1, 0.25),\n",
    "    (0.25, 0.50),\n",
    "    (0.50, 0.75),\n",
    "    (0.75, 1.0),\n",
    "    (1.0, 1.25),\n",
    "    (1.25, 1.50),\n",
    "    (1.50, 1.75),\n",
    "    (1.75, 2.0),\n",
    "]\n",
    "\n",
    "# Generate the paths for it.\n",
    "output_path, figure_path = setup_simulation_paths( simID )\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"{'Simulation ID:':<18} {simID}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"• Simulation Data:\")\n",
    "print(f\"    - Generates a synthetic proteomics dataset with {n_proteins} proteins.\")\n",
    "print(f\"    - Each protein has {n_peptides[0]}–{n_peptides[1]} peptides, across {n_condition} conditions.\")\n",
    "print(f\"    - The first condition is the control; the rest are experimental.\")\n",
    "print(f\"    - Uses the random (2 to 50%) peptide perturbation strategy as the base and adds different levels of missingness.\")\n",
    "print(\"• Simulation Goal:\")\n",
    "print(\"    - To evaluate the effect of different perturbation magnitude ranges on downstream analyses.\")\n",
    "print(\"• Parameters:\")\n",
    "print(f\"    - RNG seed: {seed}\")\n",
    "print(f\"    - {n_condition} conditions (control + {n_condition-1} treatments), log2 shifts: {condition_shifts}\")\n",
    "print(f\"    - {n_proteins} proteins × {n_replicates} replicates, {n_peptides[0]}–{n_peptides[1]} peptides/protein\")\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins (overlap={perturb_overlap})\")\n",
    "print(f\"    - Perturbation in conditions: {perturb_conds}\")\n",
    "print(f\"    - Perturbation magnitude ranges tested: \\n       {perturbationRanges}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "print(\"• Step 1: Generate Protein Mean Values (with outliers)\")\n",
    "print(f\"    - Using seed: {seed}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "print(\"• Step 1: Generate Protein Mean Values (with outliers)\")\n",
    "print(f\"    - Using seed: {seed}\")\n",
    "mean_values = sims.normal_distribution_with_outliers(\n",
    "    mu=20,\n",
    "    sd=2,\n",
    "    size=n_proteins,\n",
    "    is_log2=False,\n",
    "    outlier_fraction=0.10,\n",
    "    outlier_sd_multiplier=1.0,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Generated {len(mean_values)} protein mean values (log2 scale)\")\n",
    "print(f\"    - Stats: mean={np.mean(mean_values):.2f}, std={np.std(mean_values):.2f}, min={np.min(mean_values):.2f}, max={np.max(mean_values):.2f}\")\n",
    "print(f\"    - Outliers: fraction=10.0%, sd-multiplier=1.0\")\n",
    "mean_values = 2 ** mean_values\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 2: Generate Protein Coefficient of Variation (CV) Values\")\n",
    "cv_values = sims.lognormal_distribution(\n",
    "    mu=10,\n",
    "    med=8,\n",
    "    size=n_proteins,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Log-normal distribution: mean=10, median=8\")\n",
    "print(f\"    - Generated {len(cv_values)} CV values\")\n",
    "print(f\"    - Stats: mean={np.mean(cv_values):.2f}, std={np.std(cv_values):.2f}, min={np.min(cv_values):.2f}, max={np.max(cv_values):.2f}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 3: Generate Replicates for Control (Biological Reference)\")\n",
    "control_data = sims.generate_replicates(\n",
    "    mean_values,\n",
    "    cv_values,\n",
    "    meanScale='raw',\n",
    "    cvType='percent',\n",
    "    nReps=n_replicates,\n",
    "    randomizeCV=True,\n",
    "    as_dataframe=True,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Generated {control_data.shape[1]} control replicates for {control_data.shape[0]} proteins\")\n",
    "print(f\"    - This subset will serve as the control for all treatments.\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 4: Generate Number of Peptides per Protein\")\n",
    "pepN_cnts = sims.generate_peptide_counts(\n",
    "    n_proteins=n_proteins,\n",
    "    min_peptides=n_peptides[0],\n",
    "    max_peptides=n_peptides[1],\n",
    "    alpha=0.5,\n",
    "    beta=3,\n",
    ")\n",
    "print(f\"    - Beta-binomial: min={n_peptides[0]}, max={n_peptides[1]}, alpha=0.5, beta=3\")\n",
    "print(f\"    - Generated {len(pepN_cnts)} peptide counts\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 5: Generate Peptide-Level Data from Protein-Level Data\")\n",
    "pep_data = sims.generate_peptide_level(\n",
    "    control_data,\n",
    "    pepN_cnts,\n",
    "    is_log2=False,\n",
    "    repStd=(0.1, 0.25),\n",
    "    outlier_fraction=0.0001,\n",
    "    outlier_multiplier=0.01,\n",
    "    add_noise=True,\n",
    "    noise_sd=0.10,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Peptide-level data: {pep_data.shape[0]} peptides × {pep_data.shape[1]} samples\")\n",
    "print(f\"    - Noise: sd=0.10, Outliers: fraction=0.0001, multiplier=0.01\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 6: Generate Condition Mappers\")\n",
    "condition_sample_map, condition_shifts = sims.generate_condition_mappers(\n",
    "    n_condition=n_condition-1,\n",
    "    n_replicates=n_replicates,\n",
    "    condition_shifts=condition_shifts[1:],\n",
    "    control_name='control',\n",
    "    condition_suffix='cond',\n",
    ")\n",
    "print(f\"    - Condition sample map keys: {list(condition_sample_map.keys())}\")\n",
    "print(f\"    - Condition shifts: {condition_shifts}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 7: Generate Complete Peptide-Level Data for All Conditions\")\n",
    "generated_data = sims.generate_complete_data(\n",
    "    pep_data,\n",
    "    condition_shifts=condition_shifts,\n",
    "    condition_sample_map=condition_sample_map,\n",
    "    shift_scale=0.10,\n",
    "    is_log2=False,\n",
    "    add_noise=False,\n",
    "    noise_sd=0.10,\n",
    "    seed=seed\n",
    ")\n",
    "print(f\"    - Complete dataset: {generated_data.shape[0]} peptides × {generated_data.shape[1]} samples\")\n",
    "print(f\"    - Noise: sd=0.10, shift_scale=0.10, no additional noise added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cac4d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "• Step 9: Setup and Run for Different Levels of Missingness\n",
      "    - Running for 16 combinations of perturbation magnitude ranges:\n",
      "     - Version = Perturbation Magnitude Range: (0.1, 0.25), saving as: 2_0.1_0.25_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (0.25, 0.5), saving as: 2_0.25_0.5_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (0.5, 0.75), saving as: 2_0.5_0.75_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (0.75, 1.0), saving as: 2_0.75_1.0_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (1.0, 1.25), saving as: 2_1.0_1.25_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (1.25, 1.5), saving as: 2_1.25_1.5_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (1.5, 1.75), saving as: 2_1.5_1.75_InputData.feather\n",
      "     - Version = Perturbation Magnitude Range: (1.75, 2.0), saving as: 2_1.75_2.0_InputData.feather\n",
      "\n",
      "--------------------------------------------------\n",
      "• Completed generation of 16 versions for simulation: Sim3\n",
      "    - Elapsed time: 00h:00m:12s\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nVersions = len(perturbationRanges) * 2  # Each with complete and imputed data\n",
    "simulated_data = generated_data.copy()\n",
    "nPep_to_perturb = -1            # Number of peptides to perturb if > 1 then it is a fraction\n",
    "perturb_dir_setup = \"random\"    # Randomly perturb the direction of the perturbation [random, same]\n",
    "np.random.seed(seed)            # Set the seed\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"• Step 9: Setup and Run for Different Levels of Missingness\")\n",
    "\n",
    "print(f\"    - Running for {nVersions} combinations of perturbation magnitude ranges:\")\n",
    "for pertMag_range in perturbationRanges:\n",
    "    print(f\"     - Version = Perturbation Magnitude Range: {pertMag_range}, saving as: 2_{pertMag_range[0]}_{pertMag_range[1]}_InputData.feather\") \n",
    "    # Select random proteins to perturb\n",
    "    proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "    # Pick a fraction between 0.1 and 0.5 of the peptides to perturb\n",
    "    if nPep_to_perturb == -1:\n",
    "        nPep_array = np.random.uniform(0.1, 0.5, len(unique_proteins))\n",
    "    elif nPep_to_perturb < 1 and nPep_to_perturb > 0:\n",
    "        nPep_array = np.repeat(nPep_to_perturb, len(unique_proteins))\n",
    "    elif nPep_to_perturb >= 1:\n",
    "        nPep_array = np.repeat(nPep_to_perturb, len(unique_proteins))\n",
    "\n",
    "    # Subset the data for perturbation\n",
    "    tmp = np.log2(simulated_data).copy()\n",
    "    perturb_data = tmp.loc[proteins_to_perturb]\n",
    "    unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "\n",
    "    # Go through the proteins and perturb single peptide in each\n",
    "    dictCnt = 0\n",
    "    perturbation_map = {}\n",
    "\n",
    "    for i, protein in enumerate(proteins_to_perturb):\n",
    "        cur_data = perturb_data.loc[protein]\n",
    "        if nPep_to_perturb < 1:\n",
    "            n = int(nPep_array[i] * len(cur_data))\n",
    "            # Ensure minimum of 1 peptide is perturbed\n",
    "            if n < 2: n = 2\n",
    "        elif nPep_to_perturb >= 1:\n",
    "            n = int(nPep_to_perturb)\n",
    "        # print(f\"Protein: {protein} - Peptides: {n}, Total Peptides: {len(cur_data)}\")\n",
    "        pepNums = np.random.choice(cur_data.index, n, replace=False)\n",
    "        # Identify the conditions to perturb\n",
    "        conds = np.random.choice(perturb_conds, len(pepNums), replace=True)\n",
    "        # Identify the magnitude of perturbation\n",
    "        pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], len(pepNums))\n",
    "        #\n",
    "        if perturb_dir_setup == \"random\":\n",
    "            pertDir = np.random.choice([-1, 1], len(pepNums), replace=True)\n",
    "        elif perturb_dir_setup == \"same\":\n",
    "            # Pick random direction\n",
    "            pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "            pertDir = np.repeat(pertDir, len(pepNums))\n",
    "        \n",
    "        for j in range(len(pepNums)):\n",
    "            perturb_samples = condition_sample_map[conds[j]]\n",
    "            # Get the peptides to perturb for the current condition\n",
    "            perturb_peptide = pepNums[j]\n",
    "            # Get the perturbation peptide intensity\n",
    "            perturb_intensity = cur_data.loc[perturb_peptide, perturb_samples]\n",
    "            # Update the perturbation peptide intensity\n",
    "            perturb_intensity += pertMag[j] * pertDir[j]\n",
    "            perturb_data.loc[(protein, perturb_peptide), perturb_samples] = perturb_intensity\n",
    "            perturbation_map[dictCnt] = {\n",
    "                \"Protein\": protein,\n",
    "                \"Peptide\": perturb_peptide,\n",
    "                \"pertCondition\": conds[j],\n",
    "                \"pertShift\": pertMag[j] * pertDir[j],\n",
    "            }\n",
    "            dictCnt += 1\n",
    "\n",
    "    perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "    perturbed_data = (np.power(2, perturbed_data))\n",
    "\n",
    "    missing_data = sims.amputation(\n",
    "        data = perturbed_data,\n",
    "        unique_proteins = unique_proteins,\n",
    "        proteins_to_perturb = proteins_to_perturb,\n",
    "        condition_shifts = condition_shifts,\n",
    "        condition_sample_map = condition_sample_map,\n",
    "        n_amputate_1 = 50,\n",
    "        n_amputate_2 = 100,\n",
    "        n_amputate_3 = 50,\n",
    "        missing_rate = 0.25,\n",
    "        seed = seed\n",
    "    )\n",
    "\n",
    "    imputed_data = sims.downshifted_imputation(\n",
    "        data = missing_data,\n",
    "        condition_sample_map = condition_sample_map,\n",
    "        is_log2 = False,\n",
    "        shiftMag = 2,\n",
    "        lowPct = 0.15,\n",
    "        minValue = 8,\n",
    "        impute_all = False,\n",
    "        seed = seed\n",
    "    )\n",
    "    test_data = sims.build_test_data(\n",
    "        data = imputed_data,\n",
    "        condition_sample_map = condition_sample_map,\n",
    "        perturbation_map = perturbation_map,\n",
    "        proteins_to_perturb = proteins_to_perturb,\n",
    "        missing_data = missing_data,\n",
    "    )\n",
    "    test_data.to_feather(\n",
    "        f\"{output_path}2_{pertMag_range[0]}_{pertMag_range[1]}_InputData.feather\"\n",
    "    )\n",
    "\n",
    "elapsed = utils.prettyTimer(utils.getTime() - stTime)\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(f\"• Completed generation of {nVersions} versions for simulation: {simID}\")\n",
    "print(f\"    - Elapsed time: {elapsed}\")\n",
    "print(f\"{'-'*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcb037",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simulation 4: Complex Multi-Variable Experimental Designs\n",
    "\n",
    "**Objective:** Evaluate method robustness across experimental designs with multiple interacting factors.\n",
    "\n",
    "**Experimental Design:**\n",
    "- **Base dataset**: Same protein/peptide structure, but variable number of conditions\n",
    "- **Factors varied**:\n",
    "\n",
    "| Factor | Levels | Description |\n",
    "|--------|--------|-------------|\n",
    "| **Conditions** | 2, 3, 4, 5, 6 | Number of experimental conditions (first is control) |\n",
    "| **Overlap** | True, False | Same peptides perturbed across conditions vs. different peptides |\n",
    "| **Direction** | same, random | All perturbations in same direction vs. random up/down |\n",
    "\n",
    "- **Total combinations**: 5 × 2 × 2 = **20 datasets**\n",
    "- **Condition strategy**: \n",
    "  - 2 conditions → perturb last condition only\n",
    "  - 3+ conditions → perturb last two conditions\n",
    "- **Perturbation**: Random 10–50% pattern, magnitude 0.5–1.5 log2\n",
    "- **Data**: Imputed versions (25% baseline missingness)\n",
    "\n",
    "**Key Questions:**\n",
    "- Does adding more conditions improve detection?\n",
    "- Are overlapping perturbation patterns easier or harder to detect?\n",
    "- Does perturbation direction consistency affect accuracy?\n",
    "\n",
    "**Output Files:** `./data/Sim4/2_{N}Cond_{Overlap|NonOverlap}_{same|random}Dir_InputData.feather`\n",
    "\n",
    "### Systematic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce262fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Simulation ID:     Sim4\n",
      "==================================================\n",
      "• Simulation Data:\n",
      "    - Generates a synthetic proteomics dataset with 500 proteins.\n",
      "    - Each protein has 5–50 peptides, across multiple conditions.\n",
      "    - The first condition is the control; the rest are experimental.\n",
      "    - Uses systematic combinations of perturbation parameters.\n",
      "• Simulation Goal:\n",
      "    - To evaluate the effect of different perturbation strategies on downstream analyses.\n",
      "• Parameters:\n",
      "    - RNG seed: 42\n",
      "    - 500 proteins × 10 replicates, 5–50 peptides/protein\n",
      "    - Perturbing 250/500 proteins\n",
      "    - Number of conditions: [2, 3, 4, 5, 6]\n",
      "    - Overlap types: [True, False]\n",
      "    - Direction types: ['random', 'same']\n",
      "    - Condition strategy: 2 conditions uses last only; 3+ conditions use last two\n",
      "    - Perturbation magnitude range: (0.5, 1.5)\n",
      "    - Total combinations: 20\n",
      "==================================================\n",
      "\n",
      "• Step 1: Generate systematic combinations of datasets\n",
      "\n",
      "--- Processing 2 conditions with shifts: [0, 0.5] ---\n",
      "    [ 1/20] Generating: 2_2Cond_Overlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1']\n",
      "        - Conditions to perturb: ['cond1']\n",
      "        - Overlap: True, Direction: random\n",
      "    [ 2/20] Generating: 2_2Cond_Overlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1']\n",
      "        - Conditions to perturb: ['cond1']\n",
      "        - Overlap: True, Direction: same\n",
      "    [ 3/20] Generating: 2_2Cond_NonOverlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1']\n",
      "        - Conditions to perturb: ['cond1']\n",
      "        - Overlap: False, Direction: random\n",
      "    [ 4/20] Generating: 2_2Cond_NonOverlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1']\n",
      "        - Conditions to perturb: ['cond1']\n",
      "        - Overlap: False, Direction: same\n",
      "\n",
      "--- Processing 3 conditions with shifts: [0, 0.5, 1] ---\n",
      "    [ 5/20] Generating: 2_3Cond_Overlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2']\n",
      "        - Conditions to perturb: ['cond1', 'cond2']\n",
      "        - Overlap: True, Direction: random\n",
      "    [ 6/20] Generating: 2_3Cond_Overlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2']\n",
      "        - Conditions to perturb: ['cond1', 'cond2']\n",
      "        - Overlap: True, Direction: same\n",
      "    [ 7/20] Generating: 2_3Cond_NonOverlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2']\n",
      "        - Conditions to perturb: ['cond1', 'cond2']\n",
      "        - Overlap: False, Direction: random\n",
      "    [ 8/20] Generating: 2_3Cond_NonOverlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2']\n",
      "        - Conditions to perturb: ['cond1', 'cond2']\n",
      "        - Overlap: False, Direction: same\n",
      "\n",
      "--- Processing 4 conditions with shifts: [0, 0.5, 1, 1.5] ---\n",
      "    [ 9/20] Generating: 2_4Cond_Overlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3']\n",
      "        - Conditions to perturb: ['cond2', 'cond3']\n",
      "        - Overlap: True, Direction: random\n",
      "    [10/20] Generating: 2_4Cond_Overlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3']\n",
      "        - Conditions to perturb: ['cond2', 'cond3']\n",
      "        - Overlap: True, Direction: same\n",
      "    [11/20] Generating: 2_4Cond_NonOverlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3']\n",
      "        - Conditions to perturb: ['cond2', 'cond3']\n",
      "        - Overlap: False, Direction: random\n",
      "    [12/20] Generating: 2_4Cond_NonOverlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3']\n",
      "        - Conditions to perturb: ['cond2', 'cond3']\n",
      "        - Overlap: False, Direction: same\n",
      "\n",
      "--- Processing 5 conditions with shifts: [0, 0.5, 1, 1.5, 2] ---\n",
      "    [13/20] Generating: 2_5Cond_Overlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4']\n",
      "        - Conditions to perturb: ['cond3', 'cond4']\n",
      "        - Overlap: True, Direction: random\n",
      "    [14/20] Generating: 2_5Cond_Overlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4']\n",
      "        - Conditions to perturb: ['cond3', 'cond4']\n",
      "        - Overlap: True, Direction: same\n",
      "    [15/20] Generating: 2_5Cond_NonOverlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4']\n",
      "        - Conditions to perturb: ['cond3', 'cond4']\n",
      "        - Overlap: False, Direction: random\n",
      "    [16/20] Generating: 2_5Cond_NonOverlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4']\n",
      "        - Conditions to perturb: ['cond3', 'cond4']\n",
      "        - Overlap: False, Direction: same\n",
      "\n",
      "--- Processing 6 conditions with shifts: [0, 0.5, 1, 1.5, 2, 2.5] ---\n",
      "    [17/20] Generating: 2_6Cond_Overlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4', 'cond5']\n",
      "        - Conditions to perturb: ['cond4', 'cond5']\n",
      "        - Overlap: True, Direction: random\n",
      "    [18/20] Generating: 2_6Cond_Overlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4', 'cond5']\n",
      "        - Conditions to perturb: ['cond4', 'cond5']\n",
      "        - Overlap: True, Direction: same\n",
      "    [19/20] Generating: 2_6Cond_NonOverlap_randomDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4', 'cond5']\n",
      "        - Conditions to perturb: ['cond4', 'cond5']\n",
      "        - Overlap: False, Direction: random\n",
      "    [20/20] Generating: 2_6Cond_NonOverlap_sameDir_InputData.feather\n",
      "        - Available conditions: ['control', 'cond1', 'cond2', 'cond3', 'cond4', 'cond5']\n",
      "        - Conditions to perturb: ['cond4', 'cond5']\n",
      "        - Overlap: False, Direction: same\n",
      "\n",
      "--------------------------------------------------\n",
      "• Completed generation of 20 versions for simulation: Sim4\n",
      "    - Elapsed time: 00h:00m:36s\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stTime = utils.getTime()\n",
    "\n",
    "## Global Variables to be Used for the Simulation\n",
    "simID = \"Sim4\"                  # Simulation ID\n",
    "n_proteins = 500                # Number of proteins in the dataset\n",
    "n_replicates = 10               # Number of replicates per condition\n",
    "n_peptides = (5, 50)            # (min, max) for peptides per protein\n",
    "nPro_to_perturb = 250           # Number of proteins to perturb\n",
    "pertMag_range = (.5, 1.5)       # Range of values to perturb the peptides with (uniform)\n",
    "nPep_to_perturb = -1            # Randomly perturb between 2 and 50% of the peptides\n",
    "\n",
    "# Systematic parameter combinations\n",
    "overlap_types = [True, False]    # Overlap vs Non-overlap\n",
    "direction_types = [\"random\", \"same\"]  # Direction of perturbations\n",
    "\n",
    "# Number of conditions to generate (with shifts)\n",
    "conditions = {\n",
    "    2: [0, .5],\n",
    "    3: [0, .5, 1],\n",
    "    4: [0, .5, 1, 1.5],\n",
    "    5: [0, .5, 1, 1.5, 2],\n",
    "    6: [0, .5, 1, 1.5, 2, 2.5]\n",
    "}\n",
    "\n",
    "# Calculate total versions\n",
    "total_combinations = len(conditions) * len(overlap_types) * len(direction_types)\n",
    "\n",
    "# Seed for reproducibility\n",
    "seed = 42                       \n",
    "\n",
    "# Generate the paths for it.\n",
    "output_path, figure_path = setup_simulation_paths( simID )\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"{'Simulation ID:':<18} {simID}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"• Simulation Data:\")\n",
    "print(f\"    - Generates a synthetic proteomics dataset with {n_proteins} proteins.\")\n",
    "print(f\"    - Each protein has {n_peptides[0]}–{n_peptides[1]} peptides, across multiple conditions.\")\n",
    "print(f\"    - The first condition is the control; the rest are experimental.\")\n",
    "print(f\"    - Uses systematic combinations of perturbation parameters.\")\n",
    "print(\"• Simulation Goal:\")\n",
    "print(\"    - To evaluate the effect of different perturbation strategies on downstream analyses.\")\n",
    "print(\"• Parameters:\")\n",
    "print(f\"    - RNG seed: {seed}\")\n",
    "print(f\"    - {n_proteins} proteins × {n_replicates} replicates, {n_peptides[0]}–{n_peptides[1]} peptides/protein\")\n",
    "print(f\"    - Perturbing {nPro_to_perturb}/{n_proteins} proteins\")\n",
    "print(f\"    - Number of conditions: {list(conditions.keys())}\")\n",
    "print(f\"    - Overlap types: {overlap_types}\")\n",
    "print(f\"    - Direction types: {direction_types}\")\n",
    "print(f\"    - Condition strategy: 2 conditions uses last only; 3+ conditions use last two\")\n",
    "print(f\"    - Perturbation magnitude range: {pertMag_range}\")\n",
    "print(f\"    - Total combinations: {total_combinations}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "print(f\"• Step 1: Generate systematic combinations of datasets\")\n",
    "version_count = 0\n",
    "\n",
    "for n_condition, condition_shifts in conditions.items():\n",
    "    print(f\"\\n--- Processing {n_condition} conditions with shifts: {condition_shifts} ---\")\n",
    "    \n",
    "    # Set seed for each condition set to ensure reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create Protein Mean Values\n",
    "    mean_values = sims.normal_distribution_with_outliers(\n",
    "        mu=20, sd=2, size=n_proteins, \n",
    "        is_log2=False, outlier_fraction=0.10, \n",
    "        outlier_sd_multiplier=1.0, seed=seed\n",
    "    )\n",
    "    mean_values = 2**mean_values\n",
    "\n",
    "    # Create Protein CV Values\n",
    "    cv_values = sims.lognormal_distribution(\n",
    "        mu=10, med=8, size=n_proteins, seed=seed\n",
    "    )\n",
    "\n",
    "    # Generate replicates to have a biological sample as reference\n",
    "    control_data = sims.generate_replicates(\n",
    "        mean_values, cv_values, meanScale=\"raw\", cvType=\"percent\", \n",
    "        nReps=n_replicates, randomizeCV=True, as_dataframe=True, seed=seed\n",
    "    )\n",
    "\n",
    "    # Generate the number of peptides per protein\n",
    "    pepN_cnts = sims.generate_peptide_counts(\n",
    "        n_proteins=n_proteins, min_peptides=n_peptides[0],\n",
    "        max_peptides=n_peptides[1], alpha=.5, beta=3,\n",
    "    )\n",
    "\n",
    "    # Generate the peptide level data using the protein level data \n",
    "    pep_data = sims.generate_peptide_level(\n",
    "        control_data, pepN_cnts, is_log2=False, repStd=(0.1, 0.25),\n",
    "        outlier_fraction=0.0001, outlier_multiplier=0.01,\n",
    "        add_noise=True, noise_sd=0.10, seed=seed\n",
    "    )\n",
    "\n",
    "    # Generate Condition Mappers\n",
    "    condition_sample_map, condition_shifts_adj = sims.generate_condition_mappers(\n",
    "        n_condition=n_condition-1, n_replicates=n_replicates,\n",
    "        condition_shifts=condition_shifts[1:], control_name='control',\n",
    "        condition_suffix='cond',\n",
    "    )\n",
    "\n",
    "    # Generate the complete peptide level data with all conditions\n",
    "    complete_data = sims.generate_complete_data(\n",
    "        pep_data, condition_shifts=condition_shifts_adj,\n",
    "        condition_sample_map=condition_sample_map, shift_scale=0.10,\n",
    "        is_log2=False, add_noise=False, noise_sd=0.10, seed=seed\n",
    "    )\n",
    "    \n",
    "    # Get available conditions for perturbation\n",
    "    available_conditions = list(condition_sample_map.keys())\n",
    "    unique_proteins = complete_data.reset_index()[\"Protein\"].unique()\n",
    "    \n",
    "    # Determine conditions to perturb based on number of conditions\n",
    "    if n_condition == 2:\n",
    "        # For 2 conditions: use the last (and only) treatment condition\n",
    "        perturb_conds = [available_conditions[-1]]\n",
    "    else:\n",
    "        # For 3+ conditions: use the last two treatment conditions\n",
    "        perturb_conds = available_conditions[-2:]\n",
    "    \n",
    "    # Iterate through all parameter combinations\n",
    "    for overlap_type in overlap_types:\n",
    "        for direction_type in direction_types:\n",
    "            version_count += 1\n",
    "            \n",
    "            # Create descriptive filename\n",
    "            overlap_str = \"Overlap\" if overlap_type else \"NonOverlap\"\n",
    "            filename = f\"2_{n_condition}Cond_{overlap_str}_{direction_type}Dir_InputData.feather\"\n",
    "            \n",
    "            print(f\"    [{version_count:2d}/{total_combinations}] Generating: {filename}\")\n",
    "            print(f\"        - Available conditions: {available_conditions}\")\n",
    "            print(f\"        - Conditions to perturb: {perturb_conds}\")\n",
    "            print(f\"        - Overlap: {overlap_type}, Direction: {direction_type}\")\n",
    "\n",
    "            \n",
    "            # Reset random seed for consistent protein selection\n",
    "            np.random.seed(seed + version_count)\n",
    "            \n",
    "            simulated_data = complete_data.copy()\n",
    "            proteins_to_perturb = np.random.choice(unique_proteins, nPro_to_perturb, replace=False)\n",
    "\n",
    "            # Determine number of peptides to perturb per protein\n",
    "            if nPep_to_perturb == -1:\n",
    "                nPep_array = np.random.uniform(0.1, 0.5, len(proteins_to_perturb))\n",
    "            elif 0 < nPep_to_perturb < 1:\n",
    "                nPep_array = np.repeat(nPep_to_perturb, len(proteins_to_perturb))\n",
    "            else:\n",
    "                nPep_array = np.repeat(int(nPep_to_perturb), len(proteins_to_perturb))\n",
    "\n",
    "            # Subset the data for perturbation\n",
    "            tmp = np.log2(simulated_data).copy()\n",
    "            perturb_data = tmp.loc[proteins_to_perturb]\n",
    "            unchanged_data = tmp.drop(proteins_to_perturb)\n",
    "\n",
    "            # Apply perturbations\n",
    "            dictCnt = 0\n",
    "            perturbation_map = {}\n",
    "            \n",
    "            for i, protein in enumerate(proteins_to_perturb):\n",
    "                cur_data = perturb_data.loc[protein]\n",
    "                \n",
    "                # Determine number of peptides to perturb\n",
    "                if nPep_to_perturb < 1:\n",
    "                    n = int(nPep_array[i] * len(cur_data))\n",
    "                    if n < 2: n = 2  # Minimum 2 peptides\n",
    "                else:\n",
    "                    n = int(nPep_to_perturb)\n",
    "                \n",
    "                pepNums = np.random.choice(cur_data.index, n, replace=False)\n",
    "                \n",
    "                # Configure perturbation based on overlap and direction\n",
    "                if overlap_type:\n",
    "                    # Overlap: same peptides perturbed across multiple conditions\n",
    "                    pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], \n",
    "                                              (len(pepNums), len(perturb_conds)))\n",
    "                    if direction_type == \"random\":\n",
    "                        pertDir = np.random.choice([-1, 1], \n",
    "                                                 (len(pepNums), len(perturb_conds)), \n",
    "                                                 replace=True)\n",
    "                    else:  # \"same\"\n",
    "                        pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "                        pertDir = np.repeat(pertDir, len(pepNums) * len(perturb_conds)).reshape(\n",
    "                            (len(pepNums), len(perturb_conds)))\n",
    "                    \n",
    "                    perturb_shift = pertMag * pertDir\n",
    "                    \n",
    "                    # Apply perturbations to all conditions\n",
    "                    for j, cond in enumerate(perturb_conds):\n",
    "                        perturb_samples = condition_sample_map[cond]\n",
    "                        perturb_intensity = cur_data.loc[pepNums, perturb_samples]\n",
    "                        perturb_intensity += perturb_shift[:, j][:, np.newaxis]\n",
    "                        perturb_data.loc[(protein, pepNums), perturb_samples] = perturb_intensity.values\n",
    "                    \n",
    "                    # Update perturbation map\n",
    "                    for p, peptide in enumerate(pepNums):\n",
    "                        perturbation_map[dictCnt] = {\n",
    "                            \"Protein\": protein,\n",
    "                            \"Peptide\": peptide,\n",
    "                            \"pertCondition\": perturb_conds,\n",
    "                            \"pertShift\": perturb_shift[p, :].tolist(),\n",
    "                            \"overlapType\": overlap_str,\n",
    "                            \"directionType\": direction_type\n",
    "                        }\n",
    "                        dictCnt += 1\n",
    "                        \n",
    "                else:\n",
    "                    # Non-overlap: different peptides for different conditions\n",
    "                    pertMag = np.random.uniform(pertMag_range[0], pertMag_range[1], len(pepNums))\n",
    "                    \n",
    "                    if direction_type == \"random\":\n",
    "                        pertDir = np.random.choice([-1, 1], len(pepNums), replace=True)\n",
    "                    else:  # \"same\"\n",
    "                        pertDir = np.random.choice([-1, 1], 1, replace=True)\n",
    "                        pertDir = np.repeat(pertDir, len(pepNums))\n",
    "                    \n",
    "                    # Assign peptides to conditions (distribute evenly)\n",
    "                    peptide_conditions = np.random.choice(perturb_conds, len(pepNums), replace=True)\n",
    "                    \n",
    "                    for p, (peptide, cond) in enumerate(zip(pepNums, peptide_conditions)):\n",
    "                        perturb_samples = condition_sample_map[cond]\n",
    "                        perturb_intensity = cur_data.loc[peptide, perturb_samples]\n",
    "                        shift_value = pertMag[p] * pertDir[p]\n",
    "                        perturb_intensity += shift_value\n",
    "                        perturb_data.loc[(protein, peptide), perturb_samples] = perturb_intensity\n",
    "                        \n",
    "                        perturbation_map[dictCnt] = {\n",
    "                            \"Protein\": protein,\n",
    "                            \"Peptide\": peptide,\n",
    "                            \"pertCondition\": [cond],\n",
    "                            \"pertShift\": [shift_value],\n",
    "                            \"overlapType\": overlap_str,\n",
    "                            \"directionType\": direction_type\n",
    "                        }\n",
    "                        dictCnt += 1\n",
    "\n",
    "            # Combine perturbed and unchanged data\n",
    "            perturbed_data = pd.concat([perturb_data, unchanged_data], axis=0)\n",
    "            perturbed_data = np.power(2, perturbed_data)\n",
    "\n",
    "            # Apply missing data simulation\n",
    "            missing_data = sims.amputation(\n",
    "                data=perturbed_data, unique_proteins=unique_proteins,\n",
    "                proteins_to_perturb=proteins_to_perturb,\n",
    "                condition_shifts=condition_shifts_adj,\n",
    "                condition_sample_map=condition_sample_map,\n",
    "                n_amputate_1=50, n_amputate_2=100, n_amputate_3=50,\n",
    "                missing_rate=0.25, seed=seed + version_count\n",
    "            )\n",
    "\n",
    "            # Impute missing data\n",
    "            imputed_data = sims.downshifted_imputation(\n",
    "                data=missing_data, condition_sample_map=condition_sample_map,\n",
    "                is_log2=False, shiftMag=2, lowPct=0.15, minValue=8,\n",
    "                impute_all=False, seed=seed + version_count\n",
    "            )\n",
    "\n",
    "            # Build final test data\n",
    "            test_data = sims.build_test_data(\n",
    "                data=imputed_data, condition_sample_map=condition_sample_map,\n",
    "                perturbation_map=perturbation_map,\n",
    "                proteins_to_perturb=proteins_to_perturb,\n",
    "                missing_data=missing_data,\n",
    "            )\n",
    "\n",
    "            # Save the data\n",
    "            test_data.to_feather(f\"{output_path}{filename}\")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(f\"• Completed generation of {version_count} versions for simulation: {simID}\")\n",
    "elapsed = utils.prettyTimer(utils.getTime() - stTime)\n",
    "print(f\"    - Elapsed time: {elapsed}\")\n",
    "print(f\"{'-'*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe810b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Summary: Generated Datasets\n",
    "\n",
    "This notebook generated **61 synthetic datasets** across four simulation scenarios:\n",
    "\n",
    "| Simulation | Focus | # Datasets | Output Location |\n",
    "|------------|-------|------------|-----------------|\n",
    "| **Sim1** | Imputation effects | 8 | `./data/Sim1/` |\n",
    "| **Sim2** | Missingness tolerance | 25 | `./data/Sim2/` |\n",
    "| **Sim3** | Detection sensitivity | 8 | `./data/Sim3/` |\n",
    "| **Sim4** | Experimental complexity | 20 | `./data/Sim4/` |\n",
    "\n",
    "### Common Dataset Properties\n",
    "- **Proteins**: 500 (250 perturbed, 250 unchanged)\n",
    "- **Peptides per protein**: 5–50 (beta-binomial distribution)\n",
    "- **Replicates**: 10 per condition\n",
    "- **Ground truth**: Each dataset includes `isPerturbed` and `isOutlier` columns for benchmarking\n",
    "\n",
    "### Next Steps\n",
    "The generated datasets are used by:\n",
    "1. `02-runCOPF.R` — Run COPF method\n",
    "2. `03-runPeCorA.R` — Run PeCorA method  \n",
    "3. `04-runProteoForge.py` — Run ProteoForge method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea8eb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Execution Time: 00h:03m:04s\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook Execution Time:\", utils.prettyTimer(utils.getTime() - startTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
